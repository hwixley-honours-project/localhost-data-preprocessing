{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f7740a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7490e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = \"polar-window20-lag0-resnet152-v2\"\n",
    "save_dir = \"/ml-models/db16.4/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfff79ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph torch-jit-export (\\n  %actual_input[FLOAT, 1x1x20x75]\\n) initializers (\\n  %decoder.decoder.weight[FLOAT, 2x2048]\\n  %decoder.decoder.bias[FLOAT, 2]\\n  %1404[FLOAT, 64x1x7x7]\\n  %1405[FLOAT, 64]\\n  %1407[FLOAT, 256x64x1x1]\\n  %1408[FLOAT, 256]\\n  %1410[FLOAT, 64x64x1x1]\\n  %1411[FLOAT, 64]\\n  %1413[FLOAT, 64x64x3x3]\\n  %1414[FLOAT, 64]\\n  %1416[FLOAT, 256x64x1x1]\\n  %1417[FLOAT, 256]\\n  %1419[FLOAT, 64x256x1x1]\\n  %1420[FLOAT, 64]\\n  %1422[FLOAT, 64x64x3x3]\\n  %1423[FLOAT, 64]\\n  %1425[FLOAT, 256x64x1x1]\\n  %1426[FLOAT, 256]\\n  %1428[FLOAT, 64x256x1x1]\\n  %1429[FLOAT, 64]\\n  %1431[FLOAT, 64x64x3x3]\\n  %1432[FLOAT, 64]\\n  %1434[FLOAT, 256x64x1x1]\\n  %1435[FLOAT, 256]\\n  %1437[FLOAT, 512x256x1x1]\\n  %1438[FLOAT, 512]\\n  %1440[FLOAT, 128x256x1x1]\\n  %1441[FLOAT, 128]\\n  %1443[FLOAT, 128x128x3x3]\\n  %1444[FLOAT, 128]\\n  %1446[FLOAT, 512x128x1x1]\\n  %1447[FLOAT, 512]\\n  %1449[FLOAT, 128x512x1x1]\\n  %1450[FLOAT, 128]\\n  %1452[FLOAT, 128x128x3x3]\\n  %1453[FLOAT, 128]\\n  %1455[FLOAT, 512x128x1x1]\\n  %1456[FLOAT, 512]\\n  %1458[FLOAT, 128x512x1x1]\\n  %1459[FLOAT, 128]\\n  %1461[FLOAT, 128x128x3x3]\\n  %1462[FLOAT, 128]\\n  %1464[FLOAT, 512x128x1x1]\\n  %1465[FLOAT, 512]\\n  %1467[FLOAT, 128x512x1x1]\\n  %1468[FLOAT, 128]\\n  %1470[FLOAT, 128x128x3x3]\\n  %1471[FLOAT, 128]\\n  %1473[FLOAT, 512x128x1x1]\\n  %1474[FLOAT, 512]\\n  %1476[FLOAT, 128x512x1x1]\\n  %1477[FLOAT, 128]\\n  %1479[FLOAT, 128x128x3x3]\\n  %1480[FLOAT, 128]\\n  %1482[FLOAT, 512x128x1x1]\\n  %1483[FLOAT, 512]\\n  %1485[FLOAT, 128x512x1x1]\\n  %1486[FLOAT, 128]\\n  %1488[FLOAT, 128x128x3x3]\\n  %1489[FLOAT, 128]\\n  %1491[FLOAT, 512x128x1x1]\\n  %1492[FLOAT, 512]\\n  %1494[FLOAT, 128x512x1x1]\\n  %1495[FLOAT, 128]\\n  %1497[FLOAT, 128x128x3x3]\\n  %1498[FLOAT, 128]\\n  %1500[FLOAT, 512x128x1x1]\\n  %1501[FLOAT, 512]\\n  %1503[FLOAT, 128x512x1x1]\\n  %1504[FLOAT, 128]\\n  %1506[FLOAT, 128x128x3x3]\\n  %1507[FLOAT, 128]\\n  %1509[FLOAT, 512x128x1x1]\\n  %1510[FLOAT, 512]\\n  %1512[FLOAT, 1024x512x1x1]\\n  %1513[FLOAT, 1024]\\n  %1515[FLOAT, 256x512x1x1]\\n  %1516[FLOAT, 256]\\n  %1518[FLOAT, 256x256x3x3]\\n  %1519[FLOAT, 256]\\n  %1521[FLOAT, 1024x256x1x1]\\n  %1522[FLOAT, 1024]\\n  %1524[FLOAT, 256x1024x1x1]\\n  %1525[FLOAT, 256]\\n  %1527[FLOAT, 256x256x3x3]\\n  %1528[FLOAT, 256]\\n  %1530[FLOAT, 1024x256x1x1]\\n  %1531[FLOAT, 1024]\\n  %1533[FLOAT, 256x1024x1x1]\\n  %1534[FLOAT, 256]\\n  %1536[FLOAT, 256x256x3x3]\\n  %1537[FLOAT, 256]\\n  %1539[FLOAT, 1024x256x1x1]\\n  %1540[FLOAT, 1024]\\n  %1542[FLOAT, 256x1024x1x1]\\n  %1543[FLOAT, 256]\\n  %1545[FLOAT, 256x256x3x3]\\n  %1546[FLOAT, 256]\\n  %1548[FLOAT, 1024x256x1x1]\\n  %1549[FLOAT, 1024]\\n  %1551[FLOAT, 256x1024x1x1]\\n  %1552[FLOAT, 256]\\n  %1554[FLOAT, 256x256x3x3]\\n  %1555[FLOAT, 256]\\n  %1557[FLOAT, 1024x256x1x1]\\n  %1558[FLOAT, 1024]\\n  %1560[FLOAT, 256x1024x1x1]\\n  %1561[FLOAT, 256]\\n  %1563[FLOAT, 256x256x3x3]\\n  %1564[FLOAT, 256]\\n  %1566[FLOAT, 1024x256x1x1]\\n  %1567[FLOAT, 1024]\\n  %1569[FLOAT, 256x1024x1x1]\\n  %1570[FLOAT, 256]\\n  %1572[FLOAT, 256x256x3x3]\\n  %1573[FLOAT, 256]\\n  %1575[FLOAT, 1024x256x1x1]\\n  %1576[FLOAT, 1024]\\n  %1578[FLOAT, 256x1024x1x1]\\n  %1579[FLOAT, 256]\\n  %1581[FLOAT, 256x256x3x3]\\n  %1582[FLOAT, 256]\\n  %1584[FLOAT, 1024x256x1x1]\\n  %1585[FLOAT, 1024]\\n  %1587[FLOAT, 256x1024x1x1]\\n  %1588[FLOAT, 256]\\n  %1590[FLOAT, 256x256x3x3]\\n  %1591[FLOAT, 256]\\n  %1593[FLOAT, 1024x256x1x1]\\n  %1594[FLOAT, 1024]\\n  %1596[FLOAT, 256x1024x1x1]\\n  %1597[FLOAT, 256]\\n  %1599[FLOAT, 256x256x3x3]\\n  %1600[FLOAT, 256]\\n  %1602[FLOAT, 1024x256x1x1]\\n  %1603[FLOAT, 1024]\\n  %1605[FLOAT, 256x1024x1x1]\\n  %1606[FLOAT, 256]\\n  %1608[FLOAT, 256x256x3x3]\\n  %1609[FLOAT, 256]\\n  %1611[FLOAT, 1024x256x1x1]\\n  %1612[FLOAT, 1024]\\n  %1614[FLOAT, 256x1024x1x1]\\n  %1615[FLOAT, 256]\\n  %1617[FLOAT, 256x256x3x3]\\n  %1618[FLOAT, 256]\\n  %1620[FLOAT, 1024x256x1x1]\\n  %1621[FLOAT, 1024]\\n  %1623[FLOAT, 256x1024x1x1]\\n  %1624[FLOAT, 256]\\n  %1626[FLOAT, 256x256x3x3]\\n  %1627[FLOAT, 256]\\n  %1629[FLOAT, 1024x256x1x1]\\n  %1630[FLOAT, 1024]\\n  %1632[FLOAT, 256x1024x1x1]\\n  %1633[FLOAT, 256]\\n  %1635[FLOAT, 256x256x3x3]\\n  %1636[FLOAT, 256]\\n  %1638[FLOAT, 1024x256x1x1]\\n  %1639[FLOAT, 1024]\\n  %1641[FLOAT, 256x1024x1x1]\\n  %1642[FLOAT, 256]\\n  %1644[FLOAT, 256x256x3x3]\\n  %1645[FLOAT, 256]\\n  %1647[FLOAT, 1024x256x1x1]\\n  %1648[FLOAT, 1024]\\n  %1650[FLOAT, 256x1024x1x1]\\n  %1651[FLOAT, 256]\\n  %1653[FLOAT, 256x256x3x3]\\n  %1654[FLOAT, 256]\\n  %1656[FLOAT, 1024x256x1x1]\\n  %1657[FLOAT, 1024]\\n  %1659[FLOAT, 256x1024x1x1]\\n  %1660[FLOAT, 256]\\n  %1662[FLOAT, 256x256x3x3]\\n  %1663[FLOAT, 256]\\n  %1665[FLOAT, 1024x256x1x1]\\n  %1666[FLOAT, 1024]\\n  %1668[FLOAT, 256x1024x1x1]\\n  %1669[FLOAT, 256]\\n  %1671[FLOAT, 256x256x3x3]\\n  %1672[FLOAT, 256]\\n  %1674[FLOAT, 1024x256x1x1]\\n  %1675[FLOAT, 1024]\\n  %1677[FLOAT, 256x1024x1x1]\\n  %1678[FLOAT, 256]\\n  %1680[FLOAT, 256x256x3x3]\\n  %1681[FLOAT, 256]\\n  %1683[FLOAT, 1024x256x1x1]\\n  %1684[FLOAT, 1024]\\n  %1686[FLOAT, 256x1024x1x1]\\n  %1687[FLOAT, 256]\\n  %1689[FLOAT, 256x256x3x3]\\n  %1690[FLOAT, 256]\\n  %1692[FLOAT, 1024x256x1x1]\\n  %1693[FLOAT, 1024]\\n  %1695[FLOAT, 256x1024x1x1]\\n  %1696[FLOAT, 256]\\n  %1698[FLOAT, 256x256x3x3]\\n  %1699[FLOAT, 256]\\n  %1701[FLOAT, 1024x256x1x1]\\n  %1702[FLOAT, 1024]\\n  %1704[FLOAT, 256x1024x1x1]\\n  %1705[FLOAT, 256]\\n  %1707[FLOAT, 256x256x3x3]\\n  %1708[FLOAT, 256]\\n  %1710[FLOAT, 1024x256x1x1]\\n  %1711[FLOAT, 1024]\\n  %1713[FLOAT, 256x1024x1x1]\\n  %1714[FLOAT, 256]\\n  %1716[FLOAT, 256x256x3x3]\\n  %1717[FLOAT, 256]\\n  %1719[FLOAT, 1024x256x1x1]\\n  %1720[FLOAT, 1024]\\n  %1722[FLOAT, 256x1024x1x1]\\n  %1723[FLOAT, 256]\\n  %1725[FLOAT, 256x256x3x3]\\n  %1726[FLOAT, 256]\\n  %1728[FLOAT, 1024x256x1x1]\\n  %1729[FLOAT, 1024]\\n  %1731[FLOAT, 256x1024x1x1]\\n  %1732[FLOAT, 256]\\n  %1734[FLOAT, 256x256x3x3]\\n  %1735[FLOAT, 256]\\n  %1737[FLOAT, 1024x256x1x1]\\n  %1738[FLOAT, 1024]\\n  %1740[FLOAT, 256x1024x1x1]\\n  %1741[FLOAT, 256]\\n  %1743[FLOAT, 256x256x3x3]\\n  %1744[FLOAT, 256]\\n  %1746[FLOAT, 1024x256x1x1]\\n  %1747[FLOAT, 1024]\\n  %1749[FLOAT, 256x1024x1x1]\\n  %1750[FLOAT, 256]\\n  %1752[FLOAT, 256x256x3x3]\\n  %1753[FLOAT, 256]\\n  %1755[FLOAT, 1024x256x1x1]\\n  %1756[FLOAT, 1024]\\n  %1758[FLOAT, 256x1024x1x1]\\n  %1759[FLOAT, 256]\\n  %1761[FLOAT, 256x256x3x3]\\n  %1762[FLOAT, 256]\\n  %1764[FLOAT, 1024x256x1x1]\\n  %1765[FLOAT, 1024]\\n  %1767[FLOAT, 256x1024x1x1]\\n  %1768[FLOAT, 256]\\n  %1770[FLOAT, 256x256x3x3]\\n  %1771[FLOAT, 256]\\n  %1773[FLOAT, 1024x256x1x1]\\n  %1774[FLOAT, 1024]\\n  %1776[FLOAT, 256x1024x1x1]\\n  %1777[FLOAT, 256]\\n  %1779[FLOAT, 256x256x3x3]\\n  %1780[FLOAT, 256]\\n  %1782[FLOAT, 1024x256x1x1]\\n  %1783[FLOAT, 1024]\\n  %1785[FLOAT, 256x1024x1x1]\\n  %1786[FLOAT, 256]\\n  %1788[FLOAT, 256x256x3x3]\\n  %1789[FLOAT, 256]\\n  %1791[FLOAT, 1024x256x1x1]\\n  %1792[FLOAT, 1024]\\n  %1794[FLOAT, 256x1024x1x1]\\n  %1795[FLOAT, 256]\\n  %1797[FLOAT, 256x256x3x3]\\n  %1798[FLOAT, 256]\\n  %1800[FLOAT, 1024x256x1x1]\\n  %1801[FLOAT, 1024]\\n  %1803[FLOAT, 256x1024x1x1]\\n  %1804[FLOAT, 256]\\n  %1806[FLOAT, 256x256x3x3]\\n  %1807[FLOAT, 256]\\n  %1809[FLOAT, 1024x256x1x1]\\n  %1810[FLOAT, 1024]\\n  %1812[FLOAT, 256x1024x1x1]\\n  %1813[FLOAT, 256]\\n  %1815[FLOAT, 256x256x3x3]\\n  %1816[FLOAT, 256]\\n  %1818[FLOAT, 1024x256x1x1]\\n  %1819[FLOAT, 1024]\\n  %1821[FLOAT, 256x1024x1x1]\\n  %1822[FLOAT, 256]\\n  %1824[FLOAT, 256x256x3x3]\\n  %1825[FLOAT, 256]\\n  %1827[FLOAT, 1024x256x1x1]\\n  %1828[FLOAT, 1024]\\n  %1830[FLOAT, 256x1024x1x1]\\n  %1831[FLOAT, 256]\\n  %1833[FLOAT, 256x256x3x3]\\n  %1834[FLOAT, 256]\\n  %1836[FLOAT, 1024x256x1x1]\\n  %1837[FLOAT, 1024]\\n  %1839[FLOAT, 2048x1024x1x1]\\n  %1840[FLOAT, 2048]\\n  %1842[FLOAT, 512x1024x1x1]\\n  %1843[FLOAT, 512]\\n  %1845[FLOAT, 512x512x3x3]\\n  %1846[FLOAT, 512]\\n  %1848[FLOAT, 2048x512x1x1]\\n  %1849[FLOAT, 2048]\\n  %1851[FLOAT, 512x2048x1x1]\\n  %1852[FLOAT, 512]\\n  %1854[FLOAT, 512x512x3x3]\\n  %1855[FLOAT, 512]\\n  %1857[FLOAT, 2048x512x1x1]\\n  %1858[FLOAT, 2048]\\n  %1860[FLOAT, 512x2048x1x1]\\n  %1861[FLOAT, 512]\\n  %1863[FLOAT, 512x512x3x3]\\n  %1864[FLOAT, 512]\\n  %1866[FLOAT, 2048x512x1x1]\\n  %1867[FLOAT, 2048]\\n  %1870[INT64, 2]\\n) {\\n  %input.4 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [2, 2]](%actual_input, %1404, %1405)\\n  %935 = Relu(%input.4)\\n  %input.8 = MaxPool[kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%935)\\n  %1406 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.8, %1407, %1408)\\n  %input.20 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.8, %1410, %1411)\\n  %input.24 = Relu(%input.20)\\n  %input.32 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.24, %1413, %1414)\\n  %input.36 = Relu(%input.32)\\n  %1415 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.36, %1416, %1417)\\n  %947 = Add(%1415, %1406)\\n  %input.48 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%947, %1419, %1420)\\n  %input.52 = Relu(%input.48)\\n  %input.60 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.52, %1422, %1423)\\n  %input.64 = Relu(%input.60)\\n  %1424 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.64, %1425, %1426)\\n  %956 = Add(%1424, %947)\\n  %input.76 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%956, %1428, %1429)\\n  %input.80 = Relu(%input.76)\\n  %input.88 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.80, %1431, %1432)\\n  %input.92 = Relu(%input.88)\\n  %1433 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.92, %1434, %1435)\\n  %965 = Add(%1433, %956)\\n  %1436 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%965, %1437, %1438)\\n  %input.108 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%965, %1440, %1441)\\n  %input.112 = Relu(%input.108)\\n  %input.120 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%input.112, %1443, %1444)\\n  %input.124 = Relu(%input.120)\\n  %1445 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.124, %1446, %1447)\\n  %976 = Add(%1445, %1436)\\n  %input.136 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%976, %1449, %1450)\\n  %input.140 = Relu(%input.136)\\n  %input.148 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.140, %1452, %1453)\\n  %input.152 = Relu(%input.148)\\n  %1454 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.152, %1455, %1456)\\n  %985 = Add(%1454, %976)\\n  %input.164 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%985, %1458, %1459)\\n  %input.168 = Relu(%input.164)\\n  %input.176 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.168, %1461, %1462)\\n  %input.180 = Relu(%input.176)\\n  %1463 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.180, %1464, %1465)\\n  %994 = Add(%1463, %985)\\n  %input.192 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%994, %1467, %1468)\\n  %input.196 = Relu(%input.192)\\n  %input.204 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.196, %1470, %1471)\\n  %input.208 = Relu(%input.204)\\n  %1472 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.208, %1473, %1474)\\n  %1003 = Add(%1472, %994)\\n  %input.220 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1003, %1476, %1477)\\n  %input.224 = Relu(%input.220)\\n  %input.232 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.224, %1479, %1480)\\n  %input.236 = Relu(%input.232)\\n  %1481 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.236, %1482, %1483)\\n  %1012 = Add(%1481, %1003)\\n  %input.248 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1012, %1485, %1486)\\n  %input.252 = Relu(%input.248)\\n  %input.260 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.252, %1488, %1489)\\n  %input.264 = Relu(%input.260)\\n  %1490 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.264, %1491, %1492)\\n  %1021 = Add(%1490, %1012)\\n  %input.276 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1021, %1494, %1495)\\n  %input.280 = Relu(%input.276)\\n  %input.288 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.280, %1497, %1498)\\n  %input.292 = Relu(%input.288)\\n  %1499 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.292, %1500, %1501)\\n  %1030 = Add(%1499, %1021)\\n  %input.304 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1030, %1503, %1504)\\n  %input.308 = Relu(%input.304)\\n  %input.316 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.308, %1506, %1507)\\n  %input.320 = Relu(%input.316)\\n  %1508 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.320, %1509, %1510)\\n  %1039 = Add(%1508, %1030)\\n  %1511 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%1039, %1512, %1513)\\n  %input.336 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1039, %1515, %1516)\\n  %input.340 = Relu(%input.336)\\n  %input.348 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%input.340, %1518, %1519)\\n  %input.352 = Relu(%input.348)\\n  %1520 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.352, %1521, %1522)\\n  %1050 = Add(%1520, %1511)\\n  %input.364 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1050, %1524, %1525)\\n  %input.368 = Relu(%input.364)\\n  %input.376 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.368, %1527, %1528)\\n  %input.380 = Relu(%input.376)\\n  %1529 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.380, %1530, %1531)\\n  %1059 = Add(%1529, %1050)\\n  %input.392 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1059, %1533, %1534)\\n  %input.396 = Relu(%input.392)\\n  %input.404 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.396, %1536, %1537)\\n  %input.408 = Relu(%input.404)\\n  %1538 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.408, %1539, %1540)\\n  %1068 = Add(%1538, %1059)\\n  %input.420 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1068, %1542, %1543)\\n  %input.424 = Relu(%input.420)\\n  %input.432 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.424, %1545, %1546)\\n  %input.436 = Relu(%input.432)\\n  %1547 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.436, %1548, %1549)\\n  %1077 = Add(%1547, %1068)\\n  %input.448 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1077, %1551, %1552)\\n  %input.452 = Relu(%input.448)\\n  %input.460 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.452, %1554, %1555)\\n  %input.464 = Relu(%input.460)\\n  %1556 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.464, %1557, %1558)\\n  %1086 = Add(%1556, %1077)\\n  %input.476 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1086, %1560, %1561)\\n  %input.480 = Relu(%input.476)\\n  %input.488 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.480, %1563, %1564)\\n  %input.492 = Relu(%input.488)\\n  %1565 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.492, %1566, %1567)\\n  %1095 = Add(%1565, %1086)\\n  %input.504 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1095, %1569, %1570)\\n  %input.508 = Relu(%input.504)\\n  %input.516 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.508, %1572, %1573)\\n  %input.520 = Relu(%input.516)\\n  %1574 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.520, %1575, %1576)\\n  %1104 = Add(%1574, %1095)\\n  %input.532 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1104, %1578, %1579)\\n  %input.536 = Relu(%input.532)\\n  %input.544 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.536, %1581, %1582)\\n  %input.548 = Relu(%input.544)\\n  %1583 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.548, %1584, %1585)\\n  %1113 = Add(%1583, %1104)\\n  %input.560 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1113, %1587, %1588)\\n  %input.564 = Relu(%input.560)\\n  %input.572 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.564, %1590, %1591)\\n  %input.576 = Relu(%input.572)\\n  %1592 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.576, %1593, %1594)\\n  %1122 = Add(%1592, %1113)\\n  %input.588 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1122, %1596, %1597)\\n  %input.592 = Relu(%input.588)\\n  %input.600 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.592, %1599, %1600)\\n  %input.604 = Relu(%input.600)\\n  %1601 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.604, %1602, %1603)\\n  %1131 = Add(%1601, %1122)\\n  %input.616 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1131, %1605, %1606)\\n  %input.620 = Relu(%input.616)\\n  %input.628 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.620, %1608, %1609)\\n  %input.632 = Relu(%input.628)\\n  %1610 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.632, %1611, %1612)\\n  %1140 = Add(%1610, %1131)\\n  %input.644 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1140, %1614, %1615)\\n  %input.648 = Relu(%input.644)\\n  %input.656 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.648, %1617, %1618)\\n  %input.660 = Relu(%input.656)\\n  %1619 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.660, %1620, %1621)\\n  %1149 = Add(%1619, %1140)\\n  %input.672 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1149, %1623, %1624)\\n  %input.676 = Relu(%input.672)\\n  %input.684 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.676, %1626, %1627)\\n  %input.688 = Relu(%input.684)\\n  %1628 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.688, %1629, %1630)\\n  %1158 = Add(%1628, %1149)\\n  %input.700 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1158, %1632, %1633)\\n  %input.704 = Relu(%input.700)\\n  %input.712 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.704, %1635, %1636)\\n  %input.716 = Relu(%input.712)\\n  %1637 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.716, %1638, %1639)\\n  %1167 = Add(%1637, %1158)\\n  %input.728 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1167, %1641, %1642)\\n  %input.732 = Relu(%input.728)\\n  %input.740 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.732, %1644, %1645)\\n  %input.744 = Relu(%input.740)\\n  %1646 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.744, %1647, %1648)\\n  %1176 = Add(%1646, %1167)\\n  %input.756 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1176, %1650, %1651)\\n  %input.760 = Relu(%input.756)\\n  %input.768 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.760, %1653, %1654)\\n  %input.772 = Relu(%input.768)\\n  %1655 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.772, %1656, %1657)\\n  %1185 = Add(%1655, %1176)\\n  %input.784 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1185, %1659, %1660)\\n  %input.788 = Relu(%input.784)\\n  %input.796 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.788, %1662, %1663)\\n  %input.800 = Relu(%input.796)\\n  %1664 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.800, %1665, %1666)\\n  %1194 = Add(%1664, %1185)\\n  %input.812 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1194, %1668, %1669)\\n  %input.816 = Relu(%input.812)\\n  %input.824 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.816, %1671, %1672)\\n  %input.828 = Relu(%input.824)\\n  %1673 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.828, %1674, %1675)\\n  %1203 = Add(%1673, %1194)\\n  %input.840 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1203, %1677, %1678)\\n  %input.844 = Relu(%input.840)\\n  %input.852 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.844, %1680, %1681)\\n  %input.856 = Relu(%input.852)\\n  %1682 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.856, %1683, %1684)\\n  %1212 = Add(%1682, %1203)\\n  %input.868 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1212, %1686, %1687)\\n  %input.872 = Relu(%input.868)\\n  %input.880 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.872, %1689, %1690)\\n  %input.884 = Relu(%input.880)\\n  %1691 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.884, %1692, %1693)\\n  %1221 = Add(%1691, %1212)\\n  %input.896 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1221, %1695, %1696)\\n  %input.900 = Relu(%input.896)\\n  %input.908 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.900, %1698, %1699)\\n  %input.912 = Relu(%input.908)\\n  %1700 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.912, %1701, %1702)\\n  %1230 = Add(%1700, %1221)\\n  %input.924 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1230, %1704, %1705)\\n  %input.928 = Relu(%input.924)\\n  %input.936 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.928, %1707, %1708)\\n  %input.940 = Relu(%input.936)\\n  %1709 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.940, %1710, %1711)\\n  %1239 = Add(%1709, %1230)\\n  %input.952 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1239, %1713, %1714)\\n  %input.956 = Relu(%input.952)\\n  %input.964 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.956, %1716, %1717)\\n  %input.968 = Relu(%input.964)\\n  %1718 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.968, %1719, %1720)\\n  %1248 = Add(%1718, %1239)\\n  %input.980 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1248, %1722, %1723)\\n  %input.984 = Relu(%input.980)\\n  %input.992 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.984, %1725, %1726)\\n  %input.996 = Relu(%input.992)\\n  %1727 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.996, %1728, %1729)\\n  %1257 = Add(%1727, %1248)\\n  %input.1008 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1257, %1731, %1732)\\n  %input.1012 = Relu(%input.1008)\\n  %input.1020 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1012, %1734, %1735)\\n  %input.1024 = Relu(%input.1020)\\n  %1736 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1024, %1737, %1738)\\n  %1266 = Add(%1736, %1257)\\n  %input.1036 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1266, %1740, %1741)\\n  %input.1040 = Relu(%input.1036)\\n  %input.1048 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1040, %1743, %1744)\\n  %input.1052 = Relu(%input.1048)\\n  %1745 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1052, %1746, %1747)\\n  %1275 = Add(%1745, %1266)\\n  %input.1064 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1275, %1749, %1750)\\n  %input.1068 = Relu(%input.1064)\\n  %input.1076 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1068, %1752, %1753)\\n  %input.1080 = Relu(%input.1076)\\n  %1754 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1080, %1755, %1756)\\n  %1284 = Add(%1754, %1275)\\n  %input.1092 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1284, %1758, %1759)\\n  %input.1096 = Relu(%input.1092)\\n  %input.1104 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1096, %1761, %1762)\\n  %input.1108 = Relu(%input.1104)\\n  %1763 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1108, %1764, %1765)\\n  %1293 = Add(%1763, %1284)\\n  %input.1120 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1293, %1767, %1768)\\n  %input.1124 = Relu(%input.1120)\\n  %input.1132 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1124, %1770, %1771)\\n  %input.1136 = Relu(%input.1132)\\n  %1772 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1136, %1773, %1774)\\n  %1302 = Add(%1772, %1293)\\n  %input.1148 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1302, %1776, %1777)\\n  %input.1152 = Relu(%input.1148)\\n  %input.1160 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1152, %1779, %1780)\\n  %input.1164 = Relu(%input.1160)\\n  %1781 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1164, %1782, %1783)\\n  %1311 = Add(%1781, %1302)\\n  %input.1176 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1311, %1785, %1786)\\n  %input.1180 = Relu(%input.1176)\\n  %input.1188 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1180, %1788, %1789)\\n  %input.1192 = Relu(%input.1188)\\n  %1790 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1192, %1791, %1792)\\n  %1320 = Add(%1790, %1311)\\n  %input.1204 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1320, %1794, %1795)\\n  %input.1208 = Relu(%input.1204)\\n  %input.1216 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1208, %1797, %1798)\\n  %input.1220 = Relu(%input.1216)\\n  %1799 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1220, %1800, %1801)\\n  %1329 = Add(%1799, %1320)\\n  %input.1232 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1329, %1803, %1804)\\n  %input.1236 = Relu(%input.1232)\\n  %input.1244 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1236, %1806, %1807)\\n  %input.1248 = Relu(%input.1244)\\n  %1808 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1248, %1809, %1810)\\n  %1338 = Add(%1808, %1329)\\n  %input.1260 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1338, %1812, %1813)\\n  %input.1264 = Relu(%input.1260)\\n  %input.1272 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1264, %1815, %1816)\\n  %input.1276 = Relu(%input.1272)\\n  %1817 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1276, %1818, %1819)\\n  %1347 = Add(%1817, %1338)\\n  %input.1288 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1347, %1821, %1822)\\n  %input.1292 = Relu(%input.1288)\\n  %input.1300 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1292, %1824, %1825)\\n  %input.1304 = Relu(%input.1300)\\n  %1826 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1304, %1827, %1828)\\n  %1356 = Add(%1826, %1347)\\n  %input.1316 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1356, %1830, %1831)\\n  %input.1320 = Relu(%input.1316)\\n  %input.1328 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1320, %1833, %1834)\\n  %input.1332 = Relu(%input.1328)\\n  %1835 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1332, %1836, %1837)\\n  %1365 = Add(%1835, %1356)\\n  %1838 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%1365, %1839, %1840)\\n  %input.1348 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1365, %1842, %1843)\\n  %input.1352 = Relu(%input.1348)\\n  %input.1360 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%input.1352, %1845, %1846)\\n  %input.1364 = Relu(%input.1360)\\n  %1847 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1364, %1848, %1849)\\n  %1376 = Add(%1847, %1838)\\n  %input.1376 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1376, %1851, %1852)\\n  %input.1380 = Relu(%input.1376)\\n  %input.1388 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1380, %1854, %1855)\\n  %input.1392 = Relu(%input.1388)\\n  %1856 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1392, %1857, %1858)\\n  %1385 = Add(%1856, %1376)\\n  %input.1404 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1385, %1860, %1861)\\n  %input.1408 = Relu(%input.1404)\\n  %input.1416 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1408, %1863, %1864)\\n  %input.1420 = Relu(%input.1416)\\n  %1865 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.1420, %1866, %1867)\\n  %1394 = Add(%1865, %1385)\\n  %1395 = GlobalAveragePool(%1394)\\n  %input.1428 = Reshape(%1395, %1870)\\n  %output = Gemm[alpha = 1, beta = 1, transB = 1](%input.1428, %decoder.decoder.weight, %decoder.decoder.bias)\\n  return %output\\n}'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(f\"{settings}.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a Human readable representation of the graph\n",
    "onnx.helper.printable_graph(model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237aa14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7acae874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).gen_tensor_dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).gen_tensor_dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).gen_tensor_dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).gen_tensor_dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).gen_tensor_dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).gen_tensor_dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:root:scikit-learn version 1.0.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'coremltools.converters.nnssa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_206917/2171742545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnx_coreml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/onnx_coreml/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0municode_literals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# onnx-coreml version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/onnx_coreml/converter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# ML model passes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcoremltools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnssa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoreml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_pass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlmodel_passes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove_disconnected_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_conv_crop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_error_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mErrorHandling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'coremltools.converters.nnssa'"
     ]
    }
   ],
   "source": [
    "import onnx_coreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02deb2ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1828637152.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_206917/1828637152.py\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    minimum_ios_deployment_target=\"13\")\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def convert(model,\n",
    "           mode=\"classifier\",\n",
    "           image_input_names=[],\n",
    "           preprocessing_args={\"window_size\": 10, \"lag\": 200, \"features_all\": True},\n",
    "           image_output_names=[],\n",
    "           class_labels=[\"no-fall\",\"fall\"],\n",
    "           predicted_feature_name=\"classLabel\",\n",
    "           add_custom_layers=False,\n",
    "           custom_conversion_functions={},\n",
    "           minimum_ios_deployment_target=\"13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359abbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976131f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d8744cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "\n",
    "tf_rep = prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b14559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_path = os.getcwd() + save_dir + f\"{settings}-tf/\"\n",
    "tflite_model_path = tf_model_path + f\"saved_model.tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7333a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hwixley/Documents/4th-Year/Honours-Project/localhost-data-preprocessing/ml-models/db16.4/polar-window20-lag0-resnet152-v2-tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hwixley/Documents/4th-Year/Honours-Project/localhost-data-preprocessing/ml-models/db16.4/polar-window20-lag0-resnet152-v2-tf/assets\n"
     ]
    }
   ],
   "source": [
    "tf_rep.export_graph(tf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b3d023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6fbd1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hwixley/Documents/4th-Year/Honours-Project/localhost-data-preprocessing/ml-models/db16.4/polar-window20-lag0-resnet152-v2-tf/saved_model.tflite'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad7e322d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 14:37:00.623256: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-16 14:37:01.061805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-16 14:38:16.855214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-16 14:50:35.454916: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2022-04-16 14:50:35.550014: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-04-16 14:50:54.686921: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-16 14:50:55.463057: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9072/3343121445.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'actual_input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m               *args, **kwds)\n\u001b[1;32m    893\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m       return self._concrete_stateful_fn._call_flat(\n\u001b[0m\u001b[1;32m    895\u001b[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    model = tf.saved_model.load(tf_model_path)\n",
    "    model.trainable = False\n",
    "\n",
    "    input_tensor = tf.random.uniform([1, 1, 20, 75], dtype=tf.float32)\n",
    "    out = model(**{'actual_input': input_tensor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a121db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 13:48:12.257425: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\n",
      "2022-04-16 13:48:12.257443: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\n",
      "2022-04-16 13:48:12.257446: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:325] Ignored change_concat_input_ranges.\n",
      "2022-04-16 13:48:12.257552: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /home/hwixley/Documents/4th-Year/Honours-Project/localhost-data-preprocessing/ml-models/db16.4/polar-window20-lag0-resnet152-v2-tf/\n",
      "2022-04-16 13:48:12.296505: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\n",
      "2022-04-16 13:48:12.296529: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /home/hwixley/Documents/4th-Year/Honours-Project/localhost-data-preprocessing/ml-models/db16.4/polar-window20-lag0-resnet152-v2-tf/\n",
      "2022-04-16 13:48:12.296571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-16 13:48:12.296575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "2022-04-16 13:48:12.296578: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-16 13:48:12.387165: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2022-04-16 13:48:12.460650: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /home/hwixley/Documents/4th-Year/Honours-Project/localhost-data-preprocessing/ml-models/db16.4/polar-window20-lag0-resnet152-v2-tf/\n",
      "2022-04-16 13:48:12.530400: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 272841 microseconds.\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_ops = [\n",
    "        tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "        tf.lite.OpsSet.SELECT_TF_OPS\n",
    "    ]\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model\n",
    "    with open(tflite_model_path, 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14677ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hwixley/Documents/4th-Year/Honours-Project/localhost-data-preprocessing/ml-models/db16.4/polar-window20-lag0-resnet152-tf/polar-window20-lag0-resnet152.tflite'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69dd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57c4fde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hwixley/Documents/4th-Year/Honours-Project/localhost-data-preprocessing/ml-models/db16.4/polar-window20-lag0-resnet152-tf/'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b86f18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 12:43:53.361022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 12:43:53.361115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.77GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2022-04-16 12:43:53.361135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-16 12:43:53.361152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-16 12:43:53.361159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-16 12:43:53.361165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-16 12:43:53.361171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-16 12:43:53.361178: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-16 12:43:53.361184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-16 12:43:53.361191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-16 12:43:53.361232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 12:43:53.361304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 12:43:53.361354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-16 12:43:53.361374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-16 12:43:53.361377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-04-16 12:43:53.361380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-04-16 12:43:53.361424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 12:43:53.361496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 12:43:53.361551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2387 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2022-04-16 12:43:53.361562: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore 'tcmalloc: large alloc' warnings.\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x9b in position 3: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDecodeError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_frozen_graph\u001b[0;34m(cls, graph_def_file, input_arrays, output_arrays, input_shapes)\u001b[0m\n\u001b[1;32m   1804\u001b[0m           \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m           \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_text_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDecodeError\u001b[0m: Error parsing message with type 'tensorflow.GraphDef'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9072/2089657329.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# make a converter object from the saved tensorflow file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(TF_PATH,  # TensorFlow freezegraph .pb model file\n\u001b[0m\u001b[1;32m      8\u001b[0m                                                       \u001b[0minput_arrays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# name of input arrays as defined in torch.onnx.export function before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                       \u001b[0moutput_arrays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# name of output arrays defined in torch.onnx.export function before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_frozen_graph\u001b[0;34m(cls, graph_def_file, input_arrays, output_arrays, input_shapes)\u001b[0m\n\u001b[1;32m   1812\u001b[0m                 \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m                 \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m             \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m             \u001b[0m_text_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mensure_text\u001b[0;34m(s, encoding, errors)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \"\"\"\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x9b in position 3: invalid start byte"
     ]
    }
   ],
   "source": [
    "TF_PATH = f\"{tf_model_path}/saved_model.pb\" # where the forzen graph is stored\n",
    "TFLITE_PATH = f\"{tf_model_path}/saved_model.tflite\"\n",
    "# protopuf needs your virtual environment to be explictly exported in the path\n",
    "os.environ[\"PATH\"] = \"/opt/miniconda3/envs/convert/bin:/opt/miniconda3/bin:/usr/local/sbin:....\"\n",
    "\n",
    "# make a converter object from the saved tensorflow file\n",
    "converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(TF_PATH,  # TensorFlow freezegraph .pb model file\n",
    "                                                      input_arrays=['input'], # name of input arrays as defined in torch.onnx.export function before.\n",
    "                                                      output_arrays=['output'] # name of output arrays defined in torch.onnx.export function before.\n",
    "                                                      )\n",
    "\n",
    "# tell converter which type of optimization techniques to use\n",
    "# to view the best option for optimization read documentation of tflite about optimization\n",
    "# go to this link https://www.tensorflow.org/lite/guide/get_started#4_optimize_your_model_optional\n",
    "# converter.optimizations = [tf.compat.v1.lite.Optimize.DEFAULT]\n",
    "\n",
    "converter.experimental_new_converter = True\n",
    "\n",
    "# I had to explicitly state the ops\n",
    "converter.target_spec.supported_ops = [tf.compat.v1.lite.OpsSet.TFLITE_BUILTINS,\n",
    "                                       tf.compat.v1.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "tf_lite_model = converter.convert()\n",
    "# Save the model.\n",
    "with open(TFLITE_PATH, 'wb') as f:\n",
    "    f.write(tf_lite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd129f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
