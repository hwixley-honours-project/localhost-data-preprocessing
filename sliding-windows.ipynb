{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1eb7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cc61b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePickle(data, filename):\n",
    "    with open(os.getcwd() + \"/train-val-test/\" + filename, \"wb\") as f: np.save(f, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "441b0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recording:\n",
    "    def __init__(self, meta):\n",
    "        self._id = meta._id\n",
    "        self.subject_id = meta.subject_id\n",
    "        self.phone_placement = meta.phone_placement\n",
    "        self.recording_duration = meta.recording_duration\n",
    "        self.chunk_ids = meta.chunk_ids\n",
    "        self.labels = []\n",
    "        self.p_ecg = []\n",
    "        self.p_hr = []\n",
    "        self.p_contact = []\n",
    "        self.p_acc_x = []\n",
    "        self.p_acc_y = []\n",
    "        self.p_acc_z = []\n",
    "        self.acc_x = []\n",
    "        self.acc_y = []\n",
    "        self.acc_z = []\n",
    "        self.gyr_x = []\n",
    "        self.gyr_y = []\n",
    "        self.gyr_z = []\n",
    "        self.gra_x = []\n",
    "        self.gra_y = []\n",
    "        self.gra_z = []\n",
    "        self.mag_x = []\n",
    "        self.mag_y = []\n",
    "        self.mag_z = []\n",
    "        self.att_roll = []\n",
    "        self.att_pitch = []\n",
    "        self.att_yaw = []\n",
    "        self.delta_heading = []\n",
    "        \n",
    "        print(self._id)\n",
    "        r_chunks = rec_chunks[self._id]\n",
    "        for c in r_chunks:\n",
    "            print(c._id)\n",
    "        print()\n",
    "        ordered_chunk_ids = {}\n",
    "        \n",
    "        for chunk in r_chunks:\n",
    "            ordered_chunk_ids[chunk.chunk_index] = chunk\n",
    "            \n",
    "        for i in range(1,len(r_chunks)-1):\n",
    "            chunk = chunks[ordered_chunk_ids[i]._id]\n",
    "            \n",
    "            assert(i == chunk.chunk_index)\n",
    "            \n",
    "            self.labels += chunk.labels\n",
    "            self.p_ecg += chunk.p_ecg\n",
    "            self.p_hr += chunk.p_hr\n",
    "            self.p_contact += chunk.p_contact\n",
    "            self.p_acc_x += chunk.p_acc_x\n",
    "            self.p_acc_y += chunk.p_acc_y\n",
    "            self.p_acc_z += chunk.p_acc_z\n",
    "            self.acc_x += chunk.acc_x\n",
    "            self.acc_y += chunk.acc_y\n",
    "            self.acc_z += chunk.acc_z\n",
    "            self.gyr_x += chunk.gyr_x\n",
    "            self.gyr_y += chunk.gyr_y\n",
    "            self.gyr_z += chunk.gyr_z\n",
    "            self.gra_x += chunk.gra_x\n",
    "            self.gra_y += chunk.gra_y\n",
    "            self.gra_z += chunk.gra_z\n",
    "            self.mag_x += chunk.mag_x\n",
    "            self.mag_y += chunk.mag_y\n",
    "            self.mag_z += chunk.mag_z\n",
    "            self.att_roll += chunk.att_roll\n",
    "            self.att_pitch += chunk.att_pitch\n",
    "            self.att_yaw += chunk.att_yaw\n",
    "            self.delta_heading += chunk.delta_heading\n",
    "            \n",
    "    def getIntervals(self, lag):\n",
    "        output = np.zeros((len(self.labels), 90))\n",
    "        \n",
    "        for i in range(len(self.labels)):\n",
    "            output[i,:] = IntervalData(self, i).flatten()\n",
    "        \n",
    "        return output[:-lag,:-1], output[lag:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1d5f9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntervalData:\n",
    "    def __init__(self, rec, idx):\n",
    "        self.label = rec.labels[idx]\n",
    "        self.p_ecg = rec.p_ecg[idx*13 : idx*13 + 13]\n",
    "        self.p_acc_x = rec.p_acc_x[idx*20 : idx*20 + 20]\n",
    "        self.p_acc_y = rec.p_acc_y[idx*20 : idx*20 + 20]\n",
    "        self.p_acc_z = rec.p_acc_z[idx*20 : idx*20 + 20]\n",
    "        self.acc_x = rec.acc_x[idx]\n",
    "        self.acc_y = rec.acc_y[idx]\n",
    "        self.acc_z = rec.acc_z[idx]\n",
    "        self.gyr_x = rec.gyr_x[idx]\n",
    "        self.gyr_y = rec.gyr_y[idx]\n",
    "        self.gyr_z = rec.gyr_z[idx]\n",
    "        self.gra_x = rec.gra_x[idx]\n",
    "        self.gra_y = rec.gra_y[idx]\n",
    "        self.gra_z = rec.gra_z[idx]\n",
    "        self.mag_x = rec.mag_x[idx]\n",
    "        self.mag_y = rec.mag_y[idx]\n",
    "        self.mag_z = rec.mag_z[idx]\n",
    "        self.att_roll = rec.att_roll[idx]\n",
    "        self.att_pitch = rec.att_pitch[idx]\n",
    "        self.att_yaw = rec.att_yaw[idx]\n",
    "        self.delta_heading = rec.delta_heading[idx]\n",
    "        \n",
    "    def flatten(self):\n",
    "        #size = 17*1 + 13*1 + 20*3\n",
    "        output = np.zeros((90))\n",
    "        \n",
    "        output[0:13] = np.array(self.p_ecg)\n",
    "        output[13:33] = np.array(self.p_acc_x)\n",
    "        output[33:53] = np.array(self.p_acc_y)\n",
    "        output[53:73] = np.array(self.p_acc_z)\n",
    "        output[73] = self.acc_x\n",
    "        output[74] = self.acc_y\n",
    "        output[75] = self.acc_z\n",
    "        output[76] = self.gyr_x\n",
    "        output[77] = self.gyr_y\n",
    "        output[78] = self.gyr_z\n",
    "        output[79] = self.gra_x\n",
    "        output[80] = self.gra_y\n",
    "        output[81] = self.gra_z\n",
    "        output[82] = self.mag_x\n",
    "        output[83] = self.mag_y\n",
    "        output[84] = self.mag_z\n",
    "        output[85] = self.att_roll\n",
    "        output[86] = self.att_pitch\n",
    "        output[87] = self.att_yaw\n",
    "        output[88] = self.delta_heading\n",
    "        output[89] = self.label\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8300121f",
   "metadata": {},
   "source": [
    "# Read Pickle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4893662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "83b5a190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849B275E-A5B1-4A03-A374-CCFA44F34960\n",
      "AD642CAB-2FE2-4B02-B7E7-0BC7695B6D04\n"
     ]
    }
   ],
   "source": [
    "ddir = os.getcwd() + \"/pickles/db13\"\n",
    "files = os.listdir(ddir)\n",
    "recordings = []\n",
    "\n",
    "for f in files:\n",
    "    reader = open(ddir + \"/\" + f, \"rb\")\n",
    "    rec = pickle.load(reader)\n",
    "    print(rec._id)\n",
    "    recordings.append(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34389225",
   "metadata": {},
   "source": [
    "# Parse Data Into Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8b36d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "intvls = [r.getIntervals(1) for r in recordings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2d365",
   "metadata": {},
   "source": [
    "# Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d30e049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import more_itertools as mit\n",
    "\n",
    "def window(seq, n=10):\n",
    "    return np.array([list(mit.flatten(s)) for s in mit.windowed(seq, n)])\n",
    "\n",
    "def window_1d(seq, n=10):\n",
    "    return np.lib.stride_tricks.sliding_window_view(seq, window_shape = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "bfa9a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 89)\n",
      "(199,)\n",
      "(187, 1157)\n",
      "(187, 13)\n",
      "(187,)\n",
      "\n",
      "(199, 89)\n",
      "(199,)\n",
      "(187, 1157)\n",
      "(187, 13)\n",
      "(187,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ys = []\n",
    "ys_w = []\n",
    "xs = []\n",
    "num_windows = 13\n",
    "\n",
    "for x,y in intvls:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    xs.append(window(x,num_windows))\n",
    "    ys_w.append(window_1d(y,num_windows))\n",
    "    ys.append(ys_w[-1][:,0])\n",
    "    print(xs[-1].shape)\n",
    "    print(ys_w[-1].shape)\n",
    "    print(ys[-1].shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78415836",
   "metadata": {},
   "source": [
    "## Merge windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7f66a50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n"
     ]
    }
   ],
   "source": [
    "num_rows = np.sum([x.shape[0] for x in xs])\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b463de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.zeros((num_rows, num_windows*89))\n",
    "yy = np.zeros((num_rows))\n",
    "\n",
    "offset = 0\n",
    "for i in range(len(xs)):\n",
    "    assert(xs[i].shape[0] == ys[i].shape[0])\n",
    "    \n",
    "    xx[offset : offset+xs[i].shape[0], :] = xs[i]\n",
    "    yy[offset : offset+xs[i].shape[0]] = ys[i]\n",
    "    offset += xs[i].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b881e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_re = np.zeros((num_rows))\n",
    "\n",
    "offset = 0\n",
    "for i in range(len(xs)):\n",
    "    assert(xs[i].shape[0] == ys_w[i].shape[0])\n",
    "    \n",
    "    for j in range(xs[i].shape[0]):\n",
    "        yy_re[offset+j] = np.sum([ys_w[i][j,k]**(num_windows-k) for k in range(num_windows)])\n",
    "    offset += xs[i].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "85110610",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_rs = np.zeros((num_rows))\n",
    "\n",
    "offset = 0\n",
    "for i in range(len(xs)):\n",
    "    assert(xs[i].shape[0] == ys_w[i].shape[0])\n",
    "    yy_rs[offset : offset+xs[i].shape[0]] = np.sum(ys_w[i], axis=1)\n",
    "    offset += xs[i].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "fd43cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tmp, X_test, y_tmp, y_test = train_test_split(xx, yy, test_size=0.2, train_size=0.8, random_state=42, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tmp, y_tmp, test_size=0.25, train_size=0.75, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "2fe2b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePickle(X_train, f\"db{db}/X_train.npy\")\n",
    "savePickle(X_test, f\"db{db}/X_test.npy\")\n",
    "savePickle(X_val, f\"db{db}/X_val.npy\")\n",
    "savePickle(y_train, f\"db{db}/y_train.npy\")\n",
    "savePickle(y_test, f\"db{db}/y_test.npy\")\n",
    "savePickle(y_val, f\"db{db}/y_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "58f3f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xre_tmp, Xre_test, yre_tmp, yre_test = train_test_split(xx, yy_re, test_size=0.2, train_size=0.8, random_state=42, shuffle=True)\n",
    "Xre_train, Xre_val, yre_train, yre_val = train_test_split(Xre_tmp, yre_tmp, test_size=0.25, train_size=0.75, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5be8434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePickle(Xre_train, f\"db{db}/Xre_train.npy\")\n",
    "savePickle(Xre_test, f\"db{db}/Xre_test.npy\")\n",
    "savePickle(Xre_val, f\"db{db}/Xre_val.npy\")\n",
    "savePickle(yre_train, f\"db{db}/yre_train.npy\")\n",
    "savePickle(yre_test, f\"db{db}/yre_test.npy\")\n",
    "savePickle(yre_val, f\"db{db}/yre_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4cb5bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xrs_tmp, Xrs_test, yrs_tmp, yrs_test = train_test_split(xx, yy_rs, test_size=0.2, train_size=0.8, random_state=42, shuffle=True)\n",
    "Xrs_train, Xrs_val, yrs_train, yrs_val = train_test_split(Xrs_tmp, yrs_tmp, test_size=0.25, train_size=0.75, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "4e3a4d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePickle(Xrs_train, f\"db{db}/Xrs_train.npy\")\n",
    "savePickle(Xrs_test, f\"db{db}/Xrs_test.npy\")\n",
    "savePickle(Xrs_val, f\"db{db}/Xrs_val.npy\")\n",
    "savePickle(yrs_train, f\"db{db}/yrs_train.npy\")\n",
    "savePickle(yrs_test, f\"db{db}/yrs_test.npy\")\n",
    "savePickle(yrs_val, f\"db{db}/yrs_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf4afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
