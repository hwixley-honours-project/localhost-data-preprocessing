digraph {
	graph [size="427.65,427.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140380010749360 [label="
 (512, 2)" fillcolor=darkolivegreen1]
	140380147448608 [label=AddmmBackward0]
	140380147448512 -> 140380147448608
	140380005092704 [label="decoder.decoder.bias
 (2)" fillcolor=lightblue]
	140380005092704 -> 140380147448512
	140380147448512 [label=AccumulateGrad]
	140380147447168 -> 140380147448608
	140380147447168 [label=ViewBackward0]
	140380147448320 -> 140380147447168
	140380147448320 [label=MeanBackward1]
	140380147448992 -> 140380147448320
	140380147448992 [label=AddBackward0]
	140380147449424 -> 140380147448992
	140380147449424 [label=CudnnBatchNormBackward0]
	140380147446400 -> 140380147449424
	140380147446400 [label=CudnnConvolutionBackward0]
	140380147446448 -> 140380147446400
	140380147446448 [label=ReluBackward0]
	140380147446832 -> 140380147446448
	140380147446832 [label=CudnnBatchNormBackward0]
	140380147446784 -> 140380147446832
	140380147446784 [label=CudnnConvolutionBackward0]
	140380147446016 -> 140380147446784
	140380147446016 [label=ReluBackward0]
	140380147446688 -> 140380147446016
	140380147446688 [label=CudnnBatchNormBackward0]
	140380147449808 -> 140380147446688
	140380147449808 [label=CudnnConvolutionBackward0]
	140380147448944 -> 140380147449808
	140380147448944 [label=AddBackward0]
	140380147449232 -> 140380147448944
	140380147449232 [label=CudnnBatchNormBackward0]
	140380009795840 -> 140380147449232
	140380009795840 [label=CudnnConvolutionBackward0]
	140380009796032 -> 140380009795840
	140380009796032 [label=ReluBackward0]
	140380009796176 -> 140380009796032
	140380009796176 [label=CudnnBatchNormBackward0]
	140380009796272 -> 140380009796176
	140380009796272 [label=CudnnConvolutionBackward0]
	140380009796464 -> 140380009796272
	140380009796464 [label=ReluBackward0]
	140380009796608 -> 140380009796464
	140380009796608 [label=CudnnBatchNormBackward0]
	140380009796704 -> 140380009796608
	140380009796704 [label=CudnnConvolutionBackward0]
	140380009795696 -> 140380009796704
	140380009795696 [label=AddBackward0]
	140380009796992 -> 140380009795696
	140380009796992 [label=CudnnBatchNormBackward0]
	140380009797136 -> 140380009796992
	140380009797136 [label=CudnnConvolutionBackward0]
	140380009797328 -> 140380009797136
	140380009797328 [label=ReluBackward0]
	140380009797472 -> 140380009797328
	140380009797472 [label=CudnnBatchNormBackward0]
	140380009797568 -> 140380009797472
	140380009797568 [label=CudnnConvolutionBackward0]
	140380009797760 -> 140380009797568
	140380009797760 [label=ReluBackward0]
	140380009797904 -> 140380009797760
	140380009797904 [label=CudnnBatchNormBackward0]
	140380009798000 -> 140380009797904
	140380009798000 [label=CudnnConvolutionBackward0]
	140380009798192 -> 140380009798000
	140380009798192 [label=AddBackward0]
	140380009798336 -> 140380009798192
	140380009798336 [label=CudnnBatchNormBackward0]
	140380009798480 -> 140380009798336
	140380009798480 [label=CudnnConvolutionBackward0]
	140380009798672 -> 140380009798480
	140380009798672 [label=ReluBackward0]
	140380009798816 -> 140380009798672
	140380009798816 [label=CudnnBatchNormBackward0]
	140380009798912 -> 140380009798816
	140380009798912 [label=CudnnConvolutionBackward0]
	140380009799104 -> 140380009798912
	140380009799104 [label=ReluBackward0]
	140380009799248 -> 140380009799104
	140380009799248 [label=CudnnBatchNormBackward0]
	140380009799344 -> 140380009799248
	140380009799344 [label=CudnnConvolutionBackward0]
	140380009798288 -> 140380009799344
	140380009798288 [label=AddBackward0]
	140380009799632 -> 140380009798288
	140380009799632 [label=CudnnBatchNormBackward0]
	140380009783456 -> 140380009799632
	140380009783456 [label=CudnnConvolutionBackward0]
	140380009783648 -> 140380009783456
	140380009783648 [label=ReluBackward0]
	140380009783792 -> 140380009783648
	140380009783792 [label=CudnnBatchNormBackward0]
	140380009783888 -> 140380009783792
	140380009783888 [label=CudnnConvolutionBackward0]
	140380009784080 -> 140380009783888
	140380009784080 [label=ReluBackward0]
	140380009784224 -> 140380009784080
	140380009784224 [label=CudnnBatchNormBackward0]
	140380009784320 -> 140380009784224
	140380009784320 [label=CudnnConvolutionBackward0]
	140380009799584 -> 140380009784320
	140380009799584 [label=AddBackward0]
	140380009784608 -> 140380009799584
	140380009784608 [label=CudnnBatchNormBackward0]
	140380009784752 -> 140380009784608
	140380009784752 [label=CudnnConvolutionBackward0]
	140380009784944 -> 140380009784752
	140380009784944 [label=ReluBackward0]
	140380009785088 -> 140380009784944
	140380009785088 [label=CudnnBatchNormBackward0]
	140380009785184 -> 140380009785088
	140380009785184 [label=CudnnConvolutionBackward0]
	140380009785376 -> 140380009785184
	140380009785376 [label=ReluBackward0]
	140380009785520 -> 140380009785376
	140380009785520 [label=CudnnBatchNormBackward0]
	140380009785568 -> 140380009785520
	140380009785568 [label=CudnnConvolutionBackward0]
	140380009784560 -> 140380009785568
	140380009784560 [label=AddBackward0]
	140380009785952 -> 140380009784560
	140380009785952 [label=CudnnBatchNormBackward0]
	140380009786096 -> 140380009785952
	140380009786096 [label=CudnnConvolutionBackward0]
	140380009786288 -> 140380009786096
	140380009786288 [label=ReluBackward0]
	140380009786432 -> 140380009786288
	140380009786432 [label=CudnnBatchNormBackward0]
	140380009786480 -> 140380009786432
	140380009786480 [label=CudnnConvolutionBackward0]
	140380009786768 -> 140380009786480
	140380009786768 [label=ReluBackward0]
	140380009786912 -> 140380009786768
	140380009786912 [label=CudnnBatchNormBackward0]
	140380009786960 -> 140380009786912
	140380009786960 [label=CudnnConvolutionBackward0]
	140380009785904 -> 140380009786960
	140380009785904 [label=AddBackward0]
	140380009787344 -> 140380009785904
	140380009787344 [label=CudnnBatchNormBackward0]
	140380009820320 -> 140380009787344
	140380009820320 [label=CudnnConvolutionBackward0]
	140380009820512 -> 140380009820320
	140380009820512 [label=ReluBackward0]
	140380009820656 -> 140380009820512
	140380009820656 [label=CudnnBatchNormBackward0]
	140380009820704 -> 140380009820656
	140380009820704 [label=CudnnConvolutionBackward0]
	140380009820992 -> 140380009820704
	140380009820992 [label=ReluBackward0]
	140380009821136 -> 140380009820992
	140380009821136 [label=CudnnBatchNormBackward0]
	140380009821184 -> 140380009821136
	140380009821184 [label=CudnnConvolutionBackward0]
	140380009787296 -> 140380009821184
	140380009787296 [label=AddBackward0]
	140380009821568 -> 140380009787296
	140380009821568 [label=CudnnBatchNormBackward0]
	140380009821712 -> 140380009821568
	140380009821712 [label=CudnnConvolutionBackward0]
	140380009821904 -> 140380009821712
	140380009821904 [label=ReluBackward0]
	140380009822048 -> 140380009821904
	140380009822048 [label=CudnnBatchNormBackward0]
	140380009822096 -> 140380009822048
	140380009822096 [label=CudnnConvolutionBackward0]
	140380009822384 -> 140380009822096
	140380009822384 [label=ReluBackward0]
	140380009822528 -> 140380009822384
	140380009822528 [label=CudnnBatchNormBackward0]
	140380009822576 -> 140380009822528
	140380009822576 [label=CudnnConvolutionBackward0]
	140380009821520 -> 140380009822576
	140380009821520 [label=AddBackward0]
	140380009822960 -> 140380009821520
	140380009822960 [label=CudnnBatchNormBackward0]
	140380009823104 -> 140380009822960
	140380009823104 [label=CudnnConvolutionBackward0]
	140380009823296 -> 140380009823104
	140380009823296 [label=ReluBackward0]
	140380009823440 -> 140380009823296
	140380009823440 [label=CudnnBatchNormBackward0]
	140380009823488 -> 140380009823440
	140380009823488 [label=CudnnConvolutionBackward0]
	140380009823776 -> 140380009823488
	140380009823776 [label=ReluBackward0]
	140380009823920 -> 140380009823776
	140380009823920 [label=CudnnBatchNormBackward0]
	140380009823968 -> 140380009823920
	140380009823968 [label=CudnnConvolutionBackward0]
	140380009822912 -> 140380009823968
	140380009822912 [label=AddBackward0]
	140380009832608 -> 140380009822912
	140380009832608 [label=CudnnBatchNormBackward0]
	140380009832752 -> 140380009832608
	140380009832752 [label=CudnnConvolutionBackward0]
	140380009832944 -> 140380009832752
	140380009832944 [label=ReluBackward0]
	140380009833088 -> 140380009832944
	140380009833088 [label=CudnnBatchNormBackward0]
	140380009833136 -> 140380009833088
	140380009833136 [label=CudnnConvolutionBackward0]
	140380009833424 -> 140380009833136
	140380009833424 [label=ReluBackward0]
	140380009833568 -> 140380009833424
	140380009833568 [label=CudnnBatchNormBackward0]
	140380009833616 -> 140380009833568
	140380009833616 [label=CudnnConvolutionBackward0]
	140380009832560 -> 140380009833616
	140380009832560 [label=AddBackward0]
	140380009834000 -> 140380009832560
	140380009834000 [label=CudnnBatchNormBackward0]
	140380009834144 -> 140380009834000
	140380009834144 [label=CudnnConvolutionBackward0]
	140380009834336 -> 140380009834144
	140380009834336 [label=ReluBackward0]
	140380009834480 -> 140380009834336
	140380009834480 [label=CudnnBatchNormBackward0]
	140380009834528 -> 140380009834480
	140380009834528 [label=CudnnConvolutionBackward0]
	140380009834816 -> 140380009834528
	140380009834816 [label=ReluBackward0]
	140380009834960 -> 140380009834816
	140380009834960 [label=CudnnBatchNormBackward0]
	140380009835008 -> 140380009834960
	140380009835008 [label=CudnnConvolutionBackward0]
	140380009833952 -> 140380009835008
	140380009833952 [label=AddBackward0]
	140380009835392 -> 140380009833952
	140380009835392 [label=CudnnBatchNormBackward0]
	140380009835536 -> 140380009835392
	140380009835536 [label=CudnnConvolutionBackward0]
	140380009835728 -> 140380009835536
	140380009835728 [label=ReluBackward0]
	140380009835872 -> 140380009835728
	140380009835872 [label=CudnnBatchNormBackward0]
	140380009835920 -> 140380009835872
	140380009835920 [label=CudnnConvolutionBackward0]
	140380009836208 -> 140380009835920
	140380009836208 [label=ReluBackward0]
	140380009836352 -> 140380009836208
	140380009836352 [label=CudnnBatchNormBackward0]
	140380009836400 -> 140380009836352
	140380009836400 [label=CudnnConvolutionBackward0]
	140380009835344 -> 140380009836400
	140380009835344 [label=AddBackward0]
	140380009828656 -> 140380009835344
	140380009828656 [label=CudnnBatchNormBackward0]
	140380009828800 -> 140380009828656
	140380009828800 [label=CudnnConvolutionBackward0]
	140380009828992 -> 140380009828800
	140380009828992 [label=ReluBackward0]
	140380009829136 -> 140380009828992
	140380009829136 [label=CudnnBatchNormBackward0]
	140380009829184 -> 140380009829136
	140380009829184 [label=CudnnConvolutionBackward0]
	140380009829472 -> 140380009829184
	140380009829472 [label=ReluBackward0]
	140380009829616 -> 140380009829472
	140380009829616 [label=CudnnBatchNormBackward0]
	140380009829664 -> 140380009829616
	140380009829664 [label=CudnnConvolutionBackward0]
	140380009828608 -> 140380009829664
	140380009828608 [label=AddBackward0]
	140380009830048 -> 140380009828608
	140380009830048 [label=CudnnBatchNormBackward0]
	140380009830192 -> 140380009830048
	140380009830192 [label=CudnnConvolutionBackward0]
	140380009830384 -> 140380009830192
	140380009830384 [label=ReluBackward0]
	140380009830528 -> 140380009830384
	140380009830528 [label=CudnnBatchNormBackward0]
	140380009830576 -> 140380009830528
	140380009830576 [label=CudnnConvolutionBackward0]
	140380009830864 -> 140380009830576
	140380009830864 [label=ReluBackward0]
	140380009831008 -> 140380009830864
	140380009831008 [label=CudnnBatchNormBackward0]
	140380009831056 -> 140380009831008
	140380009831056 [label=CudnnConvolutionBackward0]
	140380009830000 -> 140380009831056
	140380009830000 [label=AddBackward0]
	140380009831440 -> 140380009830000
	140380009831440 [label=CudnnBatchNormBackward0]
	140380009831584 -> 140380009831440
	140380009831584 [label=CudnnConvolutionBackward0]
	140380009831776 -> 140380009831584
	140380009831776 [label=ReluBackward0]
	140380009831920 -> 140380009831776
	140380009831920 [label=CudnnBatchNormBackward0]
	140380009831968 -> 140380009831920
	140380009831968 [label=CudnnConvolutionBackward0]
	140380009832256 -> 140380009831968
	140380009832256 [label=ReluBackward0]
	140380009832400 -> 140380009832256
	140380009832400 [label=CudnnBatchNormBackward0]
	140380009853040 -> 140380009832400
	140380009853040 [label=CudnnConvolutionBackward0]
	140380009831392 -> 140380009853040
	140380009831392 [label=AddBackward0]
	140380009853376 -> 140380009831392
	140380009853376 [label=CudnnBatchNormBackward0]
	140380009853520 -> 140380009853376
	140380009853520 [label=CudnnConvolutionBackward0]
	140380009853712 -> 140380009853520
	140380009853712 [label=ReluBackward0]
	140380009853856 -> 140380009853712
	140380009853856 [label=CudnnBatchNormBackward0]
	140380009853904 -> 140380009853856
	140380009853904 [label=CudnnConvolutionBackward0]
	140380009854192 -> 140380009853904
	140380009854192 [label=ReluBackward0]
	140380009854336 -> 140380009854192
	140380009854336 [label=CudnnBatchNormBackward0]
	140380009854384 -> 140380009854336
	140380009854384 [label=CudnnConvolutionBackward0]
	140380009853328 -> 140380009854384
	140380009853328 [label=AddBackward0]
	140380009854768 -> 140380009853328
	140380009854768 [label=CudnnBatchNormBackward0]
	140380009854912 -> 140380009854768
	140380009854912 [label=CudnnConvolutionBackward0]
	140380009855104 -> 140380009854912
	140380009855104 [label=ReluBackward0]
	140380009855248 -> 140380009855104
	140380009855248 [label=CudnnBatchNormBackward0]
	140380009855296 -> 140380009855248
	140380009855296 [label=CudnnConvolutionBackward0]
	140380009855584 -> 140380009855296
	140380009855584 [label=ReluBackward0]
	140380009855728 -> 140380009855584
	140380009855728 [label=CudnnBatchNormBackward0]
	140380009855776 -> 140380009855728
	140380009855776 [label=CudnnConvolutionBackward0]
	140380009854720 -> 140380009855776
	140380009854720 [label=AddBackward0]
	140380009856160 -> 140380009854720
	140380009856160 [label=CudnnBatchNormBackward0]
	140380009856304 -> 140380009856160
	140380009856304 [label=CudnnConvolutionBackward0]
	140380009856496 -> 140380009856304
	140380009856496 [label=ReluBackward0]
	140380009856640 -> 140380009856496
	140380009856640 [label=CudnnBatchNormBackward0]
	140380009856688 -> 140380009856640
	140380009856688 [label=CudnnConvolutionBackward0]
	140380009856976 -> 140380009856688
	140380009856976 [label=ReluBackward0]
	140380009844896 -> 140380009856976
	140380009844896 [label=CudnnBatchNormBackward0]
	140380009844944 -> 140380009844896
	140380009844944 [label=CudnnConvolutionBackward0]
	140380009856112 -> 140380009844944
	140380009856112 [label=AddBackward0]
	140380009845328 -> 140380009856112
	140380009845328 [label=CudnnBatchNormBackward0]
	140380009845472 -> 140380009845328
	140380009845472 [label=CudnnConvolutionBackward0]
	140380009845664 -> 140380009845472
	140380009845664 [label=ReluBackward0]
	140380009845808 -> 140380009845664
	140380009845808 [label=CudnnBatchNormBackward0]
	140380009845856 -> 140380009845808
	140380009845856 [label=CudnnConvolutionBackward0]
	140380009846144 -> 140380009845856
	140380009846144 [label=ReluBackward0]
	140380009846288 -> 140380009846144
	140380009846288 [label=CudnnBatchNormBackward0]
	140380009846336 -> 140380009846288
	140380009846336 [label=CudnnConvolutionBackward0]
	140380009845280 -> 140380009846336
	140380009845280 [label=AddBackward0]
	140380009846720 -> 140380009845280
	140380009846720 [label=CudnnBatchNormBackward0]
	140380009846864 -> 140380009846720
	140380009846864 [label=CudnnConvolutionBackward0]
	140380009847056 -> 140380009846864
	140380009847056 [label=ReluBackward0]
	140380009847200 -> 140380009847056
	140380009847200 [label=CudnnBatchNormBackward0]
	140380009847248 -> 140380009847200
	140380009847248 [label=CudnnConvolutionBackward0]
	140380009847536 -> 140380009847248
	140380009847536 [label=ReluBackward0]
	140380009847680 -> 140380009847536
	140380009847680 [label=CudnnBatchNormBackward0]
	140380009847728 -> 140380009847680
	140380009847728 [label=CudnnConvolutionBackward0]
	140380009846672 -> 140380009847728
	140380009846672 [label=AddBackward0]
	140380009848112 -> 140380009846672
	140380009848112 [label=CudnnBatchNormBackward0]
	140380009848256 -> 140380009848112
	140380009848256 [label=CudnnConvolutionBackward0]
	140380009848448 -> 140380009848256
	140380009848448 [label=ReluBackward0]
	140380009848592 -> 140380009848448
	140380009848592 [label=CudnnBatchNormBackward0]
	140380009848640 -> 140380009848592
	140380009848640 [label=CudnnConvolutionBackward0]
	140380009869472 -> 140380009848640
	140380009869472 [label=ReluBackward0]
	140380009869616 -> 140380009869472
	140380009869616 [label=CudnnBatchNormBackward0]
	140380009869664 -> 140380009869616
	140380009869664 [label=CudnnConvolutionBackward0]
	140380009848064 -> 140380009869664
	140380009848064 [label=AddBackward0]
	140380009870048 -> 140380009848064
	140380009870048 [label=CudnnBatchNormBackward0]
	140380009870192 -> 140380009870048
	140380009870192 [label=CudnnConvolutionBackward0]
	140380009870384 -> 140380009870192
	140380009870384 [label=ReluBackward0]
	140380009870528 -> 140380009870384
	140380009870528 [label=CudnnBatchNormBackward0]
	140380009870576 -> 140380009870528
	140380009870576 [label=CudnnConvolutionBackward0]
	140380009870864 -> 140380009870576
	140380009870864 [label=ReluBackward0]
	140380009871008 -> 140380009870864
	140380009871008 [label=CudnnBatchNormBackward0]
	140380009871056 -> 140380009871008
	140380009871056 [label=CudnnConvolutionBackward0]
	140380009870000 -> 140380009871056
	140380009870000 [label=AddBackward0]
	140380009871440 -> 140380009870000
	140380009871440 [label=CudnnBatchNormBackward0]
	140380009871584 -> 140380009871440
	140380009871584 [label=CudnnConvolutionBackward0]
	140380009871776 -> 140380009871584
	140380009871776 [label=ReluBackward0]
	140380009871920 -> 140380009871776
	140380009871920 [label=CudnnBatchNormBackward0]
	140380009871968 -> 140380009871920
	140380009871968 [label=CudnnConvolutionBackward0]
	140380009872256 -> 140380009871968
	140380009872256 [label=ReluBackward0]
	140380009872400 -> 140380009872256
	140380009872400 [label=CudnnBatchNormBackward0]
	140380009872448 -> 140380009872400
	140380009872448 [label=CudnnConvolutionBackward0]
	140380009871392 -> 140380009872448
	140380009871392 [label=AddBackward0]
	140380009872832 -> 140380009871392
	140380009872832 [label=CudnnBatchNormBackward0]
	140380009872976 -> 140380009872832
	140380009872976 [label=CudnnConvolutionBackward0]
	140380009873168 -> 140380009872976
	140380009873168 [label=ReluBackward0]
	140380009873312 -> 140380009873168
	140380009873312 [label=CudnnBatchNormBackward0]
	140380009873216 -> 140380009873312
	140380009873216 [label=CudnnConvolutionBackward0]
	140380009865520 -> 140380009873216
	140380009865520 [label=ReluBackward0]
	140380009865664 -> 140380009865520
	140380009865664 [label=CudnnBatchNormBackward0]
	140380009865712 -> 140380009865664
	140380009865712 [label=CudnnConvolutionBackward0]
	140380009872784 -> 140380009865712
	140380009872784 [label=AddBackward0]
	140380009866096 -> 140380009872784
	140380009866096 [label=CudnnBatchNormBackward0]
	140380009866240 -> 140380009866096
	140380009866240 [label=CudnnConvolutionBackward0]
	140380009866432 -> 140380009866240
	140380009866432 [label=ReluBackward0]
	140380009866576 -> 140380009866432
	140380009866576 [label=CudnnBatchNormBackward0]
	140380009866624 -> 140380009866576
	140380009866624 [label=CudnnConvolutionBackward0]
	140380009866912 -> 140380009866624
	140380009866912 [label=ReluBackward0]
	140380009867056 -> 140380009866912
	140380009867056 [label=CudnnBatchNormBackward0]
	140380009867104 -> 140380009867056
	140380009867104 [label=CudnnConvolutionBackward0]
	140380009866048 -> 140380009867104
	140380009866048 [label=AddBackward0]
	140380009867488 -> 140380009866048
	140380009867488 [label=CudnnBatchNormBackward0]
	140380009867632 -> 140380009867488
	140380009867632 [label=CudnnConvolutionBackward0]
	140380009867824 -> 140380009867632
	140380009867824 [label=ReluBackward0]
	140380009867968 -> 140380009867824
	140380009867968 [label=CudnnBatchNormBackward0]
	140380009868016 -> 140380009867968
	140380009868016 [label=CudnnConvolutionBackward0]
	140380009868304 -> 140380009868016
	140380009868304 [label=ReluBackward0]
	140380009868448 -> 140380009868304
	140380009868448 [label=CudnnBatchNormBackward0]
	140380009868496 -> 140380009868448
	140380009868496 [label=CudnnConvolutionBackward0]
	140380009867440 -> 140380009868496
	140380009867440 [label=AddBackward0]
	140380009868880 -> 140380009867440
	140380009868880 [label=CudnnBatchNormBackward0]
	140380009869024 -> 140380009868880
	140380009869024 [label=CudnnConvolutionBackward0]
	140380009869216 -> 140380009869024
	140380009869216 [label=ReluBackward0]
	140380009869264 -> 140380009869216
	140380009869264 [label=CudnnBatchNormBackward0]
	140380009787552 -> 140380009869264
	140380009787552 [label=CudnnConvolutionBackward0]
	140380009787840 -> 140380009787552
	140380009787840 [label=ReluBackward0]
	140380009787984 -> 140380009787840
	140380009787984 [label=CudnnBatchNormBackward0]
	140380009788032 -> 140380009787984
	140380009788032 [label=CudnnConvolutionBackward0]
	140380009868832 -> 140380009788032
	140380009868832 [label=AddBackward0]
	140380009788416 -> 140380009868832
	140380009788416 [label=CudnnBatchNormBackward0]
	140380009788560 -> 140380009788416
	140380009788560 [label=CudnnConvolutionBackward0]
	140380009788752 -> 140380009788560
	140380009788752 [label=ReluBackward0]
	140380009788896 -> 140380009788752
	140380009788896 [label=CudnnBatchNormBackward0]
	140380009788944 -> 140380009788896
	140380009788944 [label=CudnnConvolutionBackward0]
	140380009789232 -> 140380009788944
	140380009789232 [label=ReluBackward0]
	140380009789376 -> 140380009789232
	140380009789376 [label=CudnnBatchNormBackward0]
	140380009789424 -> 140380009789376
	140380009789424 [label=CudnnConvolutionBackward0]
	140380009788368 -> 140380009789424
	140380009788368 [label=AddBackward0]
	140380009789808 -> 140380009788368
	140380009789808 [label=CudnnBatchNormBackward0]
	140380009789952 -> 140380009789808
	140380009789952 [label=CudnnConvolutionBackward0]
	140380009790144 -> 140380009789952
	140380009790144 [label=ReluBackward0]
	140380009790288 -> 140380009790144
	140380009790288 [label=CudnnBatchNormBackward0]
	140380009790336 -> 140380009790288
	140380009790336 [label=CudnnConvolutionBackward0]
	140380009790624 -> 140380009790336
	140380009790624 [label=ReluBackward0]
	140380009790768 -> 140380009790624
	140380009790768 [label=CudnnBatchNormBackward0]
	140380009790816 -> 140380009790768
	140380009790816 [label=CudnnConvolutionBackward0]
	140380009789760 -> 140380009790816
	140380009789760 [label=AddBackward0]
	140380009791200 -> 140380009789760
	140380009791200 [label=CudnnBatchNormBackward0]
	140380009791344 -> 140380009791200
	140380009791344 [label=CudnnConvolutionBackward0]
	140380009791440 -> 140380009791344
	140380009791440 [label=ReluBackward0]
	140380009611520 -> 140380009791440
	140380009611520 [label=CudnnBatchNormBackward0]
	140380009611568 -> 140380009611520
	140380009611568 [label=CudnnConvolutionBackward0]
	140380009611856 -> 140380009611568
	140380009611856 [label=ReluBackward0]
	140380009612000 -> 140380009611856
	140380009612000 [label=CudnnBatchNormBackward0]
	140380009612048 -> 140380009612000
	140380009612048 [label=CudnnConvolutionBackward0]
	140380009791152 -> 140380009612048
	140380009791152 [label=AddBackward0]
	140380009612432 -> 140380009791152
	140380009612432 [label=CudnnBatchNormBackward0]
	140380009612576 -> 140380009612432
	140380009612576 [label=CudnnConvolutionBackward0]
	140380009612768 -> 140380009612576
	140380009612768 [label=ReluBackward0]
	140380009612912 -> 140380009612768
	140380009612912 [label=CudnnBatchNormBackward0]
	140380009612960 -> 140380009612912
	140380009612960 [label=CudnnConvolutionBackward0]
	140380009613248 -> 140380009612960
	140380009613248 [label=ReluBackward0]
	140380009613392 -> 140380009613248
	140380009613392 [label=CudnnBatchNormBackward0]
	140380009613440 -> 140380009613392
	140380009613440 [label=CudnnConvolutionBackward0]
	140380009612384 -> 140380009613440
	140380009612384 [label=AddBackward0]
	140380009613824 -> 140380009612384
	140380009613824 [label=CudnnBatchNormBackward0]
	140380009613968 -> 140380009613824
	140380009613968 [label=CudnnConvolutionBackward0]
	140380009614160 -> 140380009613968
	140380009614160 [label=ReluBackward0]
	140380009614304 -> 140380009614160
	140380009614304 [label=CudnnBatchNormBackward0]
	140380009614352 -> 140380009614304
	140380009614352 [label=CudnnConvolutionBackward0]
	140380009614640 -> 140380009614352
	140380009614640 [label=ReluBackward0]
	140380009614784 -> 140380009614640
	140380009614784 [label=CudnnBatchNormBackward0]
	140380009614832 -> 140380009614784
	140380009614832 [label=CudnnConvolutionBackward0]
	140380009613776 -> 140380009614832
	140380009613776 [label=AddBackward0]
	140380009615216 -> 140380009613776
	140380009615216 [label=CudnnBatchNormBackward0]
	140380009615312 -> 140380009615216
	140380009615312 [label=CudnnConvolutionBackward0]
	140380009771264 -> 140380009615312
	140380009771264 [label=ReluBackward0]
	140380009771408 -> 140380009771264
	140380009771408 [label=CudnnBatchNormBackward0]
	140380009771456 -> 140380009771408
	140380009771456 [label=CudnnConvolutionBackward0]
	140380009771744 -> 140380009771456
	140380009771744 [label=ReluBackward0]
	140380009771888 -> 140380009771744
	140380009771888 [label=CudnnBatchNormBackward0]
	140380009771936 -> 140380009771888
	140380009771936 [label=CudnnConvolutionBackward0]
	140380009615168 -> 140380009771936
	140380009615168 [label=AddBackward0]
	140380009772320 -> 140380009615168
	140380009772320 [label=CudnnBatchNormBackward0]
	140380009772464 -> 140380009772320
	140380009772464 [label=CudnnConvolutionBackward0]
	140380009772656 -> 140380009772464
	140380009772656 [label=ReluBackward0]
	140380009772800 -> 140380009772656
	140380009772800 [label=CudnnBatchNormBackward0]
	140380009772848 -> 140380009772800
	140380009772848 [label=CudnnConvolutionBackward0]
	140380009773136 -> 140380009772848
	140380009773136 [label=ReluBackward0]
	140380009773280 -> 140380009773136
	140380009773280 [label=CudnnBatchNormBackward0]
	140380009773328 -> 140380009773280
	140380009773328 [label=CudnnConvolutionBackward0]
	140380009772272 -> 140380009773328
	140380009772272 [label=AddBackward0]
	140380009773712 -> 140380009772272
	140380009773712 [label=CudnnBatchNormBackward0]
	140380009773856 -> 140380009773712
	140380009773856 [label=CudnnConvolutionBackward0]
	140380009774048 -> 140380009773856
	140380009774048 [label=ReluBackward0]
	140380009774192 -> 140380009774048
	140380009774192 [label=CudnnBatchNormBackward0]
	140380009774240 -> 140380009774192
	140380009774240 [label=CudnnConvolutionBackward0]
	140380009774528 -> 140380009774240
	140380009774528 [label=ReluBackward0]
	140380009774672 -> 140380009774528
	140380009774672 [label=CudnnBatchNormBackward0]
	140380009774720 -> 140380009774672
	140380009774720 [label=CudnnConvolutionBackward0]
	140380009773664 -> 140380009774720
	140380009773664 [label=AddBackward0]
	140380009775056 -> 140380009773664
	140380009775056 [label=CudnnBatchNormBackward0]
	140380009754832 -> 140380009775056
	140380009754832 [label=CudnnConvolutionBackward0]
	140380009755024 -> 140380009754832
	140380009755024 [label=ReluBackward0]
	140380009755168 -> 140380009755024
	140380009755168 [label=CudnnBatchNormBackward0]
	140380009755216 -> 140380009755168
	140380009755216 [label=CudnnConvolutionBackward0]
	140380009755504 -> 140380009755216
	140380009755504 [label=ReluBackward0]
	140380009755648 -> 140380009755504
	140380009755648 [label=CudnnBatchNormBackward0]
	140380009755696 -> 140380009755648
	140380009755696 [label=CudnnConvolutionBackward0]
	140380009774912 -> 140380009755696
	140380009774912 [label=AddBackward0]
	140380009756080 -> 140380009774912
	140380009756080 [label=CudnnBatchNormBackward0]
	140380009756224 -> 140380009756080
	140380009756224 [label=CudnnConvolutionBackward0]
	140380009756416 -> 140380009756224
	140380009756416 [label=ReluBackward0]
	140380009756560 -> 140380009756416
	140380009756560 [label=CudnnBatchNormBackward0]
	140380009756608 -> 140380009756560
	140380009756608 [label=CudnnConvolutionBackward0]
	140380009756896 -> 140380009756608
	140380009756896 [label=ReluBackward0]
	140380009757040 -> 140380009756896
	140380009757040 [label=CudnnBatchNormBackward0]
	140380009757088 -> 140380009757040
	140380009757088 [label=CudnnConvolutionBackward0]
	140380009756032 -> 140380009757088
	140380009756032 [label=AddBackward0]
	140380009757472 -> 140380009756032
	140380009757472 [label=CudnnBatchNormBackward0]
	140380009757616 -> 140380009757472
	140380009757616 [label=CudnnConvolutionBackward0]
	140380009757808 -> 140380009757616
	140380009757808 [label=ReluBackward0]
	140380009757952 -> 140380009757808
	140380009757952 [label=CudnnBatchNormBackward0]
	140380009758000 -> 140380009757952
	140380009758000 [label=CudnnConvolutionBackward0]
	140380009758288 -> 140380009758000
	140380009758288 [label=ReluBackward0]
	140380009758432 -> 140380009758288
	140380009758432 [label=CudnnBatchNormBackward0]
	140380009758480 -> 140380009758432
	140380009758480 [label=CudnnConvolutionBackward0]
	140380009758672 -> 140380009758480
	140380009758672 [label=AddBackward0]
	140380009758976 -> 140380009758672
	140380009758976 [label=CudnnBatchNormBackward0]
	140380009759120 -> 140380009758976
	140380009759120 [label=CudnnConvolutionBackward0]
	140380009759312 -> 140380009759120
	140380009759312 [label=ReluBackward0]
	140380009759456 -> 140380009759312
	140380009759456 [label=CudnnBatchNormBackward0]
	140380009759504 -> 140380009759456
	140380009759504 [label=CudnnConvolutionBackward0]
	140380009759792 -> 140380009759504
	140380009759792 [label=ReluBackward0]
	140380009759936 -> 140380009759792
	140380009759936 [label=CudnnBatchNormBackward0]
	140380009759984 -> 140380009759936
	140380009759984 [label=CudnnConvolutionBackward0]
	140380009758928 -> 140380009759984
	140380009758928 [label=AddBackward0]
	140380009760368 -> 140380009758928
	140380009760368 [label=CudnnBatchNormBackward0]
	140380009760512 -> 140380009760368
	140380009760512 [label=CudnnConvolutionBackward0]
	140380009760704 -> 140380009760512
	140380009760704 [label=ReluBackward0]
	140380009760848 -> 140380009760704
	140380009760848 [label=CudnnBatchNormBackward0]
	140380009760896 -> 140380009760848
	140380009760896 [label=CudnnConvolutionBackward0]
	140380009761184 -> 140380009760896
	140380009761184 [label=ReluBackward0]
	140380009761328 -> 140380009761184
	140380009761328 [label=CudnnBatchNormBackward0]
	140380009761376 -> 140380009761328
	140380009761376 [label=CudnnConvolutionBackward0]
	140380009760320 -> 140380009761376
	140380009760320 [label=AddBackward0]
	140380009761760 -> 140380009760320
	140380009761760 [label=CudnnBatchNormBackward0]
	140380009761904 -> 140380009761760
	140380009761904 [label=CudnnConvolutionBackward0]
	140380009762096 -> 140380009761904
	140380009762096 [label=ReluBackward0]
	140380009762240 -> 140380009762096
	140380009762240 [label=CudnnBatchNormBackward0]
	140380009762288 -> 140380009762240
	140380009762288 [label=CudnnConvolutionBackward0]
	140380009762576 -> 140380009762288
	140380009762576 [label=ReluBackward0]
	140380009762720 -> 140380009762576
	140380009762720 [label=CudnnBatchNormBackward0]
	140380009762624 -> 140380009762720
	140380009762624 [label=CudnnConvolutionBackward0]
	140380009761712 -> 140380009762624
	140380009761712 [label=AddBackward0]
	140380010172816 -> 140380009761712
	140380010172816 [label=CudnnBatchNormBackward0]
	140380010172960 -> 140380010172816
	140380010172960 [label=CudnnConvolutionBackward0]
	140380010173152 -> 140380010172960
	140380010173152 [label=ReluBackward0]
	140380010173296 -> 140380010173152
	140380010173296 [label=CudnnBatchNormBackward0]
	140380010173344 -> 140380010173296
	140380010173344 [label=CudnnConvolutionBackward0]
	140380010173632 -> 140380010173344
	140380010173632 [label=ReluBackward0]
	140380010173776 -> 140380010173632
	140380010173776 [label=CudnnBatchNormBackward0]
	140380010173824 -> 140380010173776
	140380010173824 [label=CudnnConvolutionBackward0]
	140380010172768 -> 140380010173824
	140380010172768 [label=AddBackward0]
	140380010174208 -> 140380010172768
	140380010174208 [label=CudnnBatchNormBackward0]
	140380010174352 -> 140380010174208
	140380010174352 [label=CudnnConvolutionBackward0]
	140380010174544 -> 140380010174352
	140380010174544 [label=ReluBackward0]
	140380010174688 -> 140380010174544
	140380010174688 [label=CudnnBatchNormBackward0]
	140380010174736 -> 140380010174688
	140380010174736 [label=CudnnConvolutionBackward0]
	140380010175024 -> 140380010174736
	140380010175024 [label=ReluBackward0]
	140380010175168 -> 140380010175024
	140380010175168 [label=CudnnBatchNormBackward0]
	140380010175216 -> 140380010175168
	140380010175216 [label=CudnnConvolutionBackward0]
	140380010174160 -> 140380010175216
	140380010174160 [label=AddBackward0]
	140380010175600 -> 140380010174160
	140380010175600 [label=CudnnBatchNormBackward0]
	140380010175744 -> 140380010175600
	140380010175744 [label=CudnnConvolutionBackward0]
	140380010175936 -> 140380010175744
	140380010175936 [label=ReluBackward0]
	140380010176080 -> 140380010175936
	140380010176080 [label=CudnnBatchNormBackward0]
	140380010176128 -> 140380010176080
	140380010176128 [label=CudnnConvolutionBackward0]
	140380010176416 -> 140380010176128
	140380010176416 [label=ReluBackward0]
	140380010176464 -> 140380010176416
	140380010176464 [label=CudnnBatchNormBackward0]
	140380010205136 -> 140380010176464
	140380010205136 [label=CudnnConvolutionBackward0]
	140380010175552 -> 140380010205136
	140380010175552 [label=AddBackward0]
	140380010204848 -> 140380010175552
	140380010204848 [label=CudnnBatchNormBackward0]
	140380010204704 -> 140380010204848
	140380010204704 [label=CudnnConvolutionBackward0]
	140380010203984 -> 140380010204704
	140380010203984 [label=ReluBackward0]
	140380010204224 -> 140380010203984
	140380010204224 [label=CudnnBatchNormBackward0]
	140380010204176 -> 140380010204224
	140380010204176 [label=CudnnConvolutionBackward0]
	140380010203888 -> 140380010204176
	140380010203888 [label=ReluBackward0]
	140380010203744 -> 140380010203888
	140380010203744 [label=CudnnBatchNormBackward0]
	140380010203696 -> 140380010203744
	140380010203696 [label=CudnnConvolutionBackward0]
	140380010204368 -> 140380010203696
	140380010204368 [label=AddBackward0]
	140380010203312 -> 140380010204368
	140380010203312 [label=CudnnBatchNormBackward0]
	140380010203168 -> 140380010203312
	140380010203168 [label=CudnnConvolutionBackward0]
	140380010202976 -> 140380010203168
	140380010202976 [label=ReluBackward0]
	140380010202448 -> 140380010202976
	140380010202448 [label=CudnnBatchNormBackward0]
	140380010202784 -> 140380010202448
	140380010202784 [label=CudnnConvolutionBackward0]
	140380010202496 -> 140380010202784
	140380010202496 [label=ReluBackward0]
	140380010202352 -> 140380010202496
	140380010202352 [label=CudnnBatchNormBackward0]
	140380010202304 -> 140380010202352
	140380010202304 [label=CudnnConvolutionBackward0]
	140380010202016 -> 140380010202304
	140380010202016 [label=AddBackward0]
	140380010201872 -> 140380010202016
	140380010201872 [label=CudnnBatchNormBackward0]
	140380010201728 -> 140380010201872
	140380010201728 [label=CudnnConvolutionBackward0]
	140380010201536 -> 140380010201728
	140380010201536 [label=ReluBackward0]
	140380010201392 -> 140380010201536
	140380010201392 [label=CudnnBatchNormBackward0]
	140380010201344 -> 140380010201392
	140380010201344 [label=CudnnConvolutionBackward0]
	140380010160288 -> 140380010201344
	140380010160288 [label=ReluBackward0]
	140380010160432 -> 140380010160288
	140380010160432 [label=CudnnBatchNormBackward0]
	140380010160480 -> 140380010160432
	140380010160480 [label=CudnnConvolutionBackward0]
	140380010201920 -> 140380010160480
	140380010201920 [label=AddBackward0]
	140380010160864 -> 140380010201920
	140380010160864 [label=CudnnBatchNormBackward0]
	140380010161008 -> 140380010160864
	140380010161008 [label=CudnnConvolutionBackward0]
	140380010161200 -> 140380010161008
	140380010161200 [label=ReluBackward0]
	140380010161344 -> 140380010161200
	140380010161344 [label=CudnnBatchNormBackward0]
	140380010161392 -> 140380010161344
	140380010161392 [label=CudnnConvolutionBackward0]
	140380010161680 -> 140380010161392
	140380010161680 [label=ReluBackward0]
	140380010161824 -> 140380010161680
	140380010161824 [label=CudnnBatchNormBackward0]
	140380010161872 -> 140380010161824
	140380010161872 [label=CudnnConvolutionBackward0]
	140380010160816 -> 140380010161872
	140380010160816 [label=AddBackward0]
	140380010162256 -> 140380010160816
	140380010162256 [label=CudnnBatchNormBackward0]
	140380010162400 -> 140380010162256
	140380010162400 [label=CudnnConvolutionBackward0]
	140380010162592 -> 140380010162400
	140380010162592 [label=ReluBackward0]
	140380010162736 -> 140380010162592
	140380010162736 [label=CudnnBatchNormBackward0]
	140380010162784 -> 140380010162736
	140380010162784 [label=CudnnConvolutionBackward0]
	140380010163072 -> 140380010162784
	140380010163072 [label=ReluBackward0]
	140380010163216 -> 140380010163072
	140380010163216 [label=CudnnBatchNormBackward0]
	140380010163264 -> 140380010163216
	140380010163264 [label=CudnnConvolutionBackward0]
	140380010163552 -> 140380010163264
	140380010163552 [label=MaxPool2DWithIndicesBackward0]
	140380010163696 -> 140380010163552
	140380010163696 [label=ReluBackward0]
	140380010163744 -> 140380010163696
	140380010163744 [label=CudnnBatchNormBackward0]
	140380010163888 -> 140380010163744
	140380010163888 [label=CudnnConvolutionBackward0]
	140380010164176 -> 140380010163888
	140380003862624 [label="encoder.gate.0.weight
 (64, 1, 7, 7)" fillcolor=lightblue]
	140380003862624 -> 140380010164176
	140380010164176 [label=AccumulateGrad]
	140380010163840 -> 140380010163744
	140380010311488 [label="encoder.gate.1.weight
 (64)" fillcolor=lightblue]
	140380010311488 -> 140380010163840
	140380010163840 [label=AccumulateGrad]
	140380010163984 -> 140380010163744
	140380010311168 [label="encoder.gate.1.bias
 (64)" fillcolor=lightblue]
	140380010311168 -> 140380010163984
	140380010163984 [label=AccumulateGrad]
	140380010163504 -> 140380010163264
	140380010308208 [label="encoder.blocks.0.blocks.0.blocks.0.conv.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	140380010308208 -> 140380010163504
	140380010163504 [label=AccumulateGrad]
	140380010163120 -> 140380010163216
	140380010311568 [label="encoder.blocks.0.blocks.0.blocks.0.bn.weight
 (64)" fillcolor=lightblue]
	140380010311568 -> 140380010163120
	140380010163120 [label=AccumulateGrad]
	140380010163360 -> 140380010163216
	140380010309328 [label="encoder.blocks.0.blocks.0.blocks.0.bn.bias
 (64)" fillcolor=lightblue]
	140380010309328 -> 140380010163360
	140380010163360 [label=AccumulateGrad]
	140380010163024 -> 140380010162784
	140380010307648 [label="encoder.blocks.0.blocks.0.blocks.2.conv.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140380010307648 -> 140380010163024
	140380010163024 [label=AccumulateGrad]
	140380010162640 -> 140380010162736
	140380010307888 [label="encoder.blocks.0.blocks.0.blocks.2.bn.weight
 (64)" fillcolor=lightblue]
	140380010307888 -> 140380010162640
	140380010162640 [label=AccumulateGrad]
	140380010162880 -> 140380010162736
	140380010308288 [label="encoder.blocks.0.blocks.0.blocks.2.bn.bias
 (64)" fillcolor=lightblue]
	140380010308288 -> 140380010162880
	140380010162880 [label=AccumulateGrad]
	140380010162544 -> 140380010162400
	140380010309248 [label="encoder.blocks.0.blocks.0.blocks.4.conv.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140380010309248 -> 140380010162544
	140380010162544 [label=AccumulateGrad]
	140380010162352 -> 140380010162256
	140380010310288 [label="encoder.blocks.0.blocks.0.blocks.4.bn.weight
 (256)" fillcolor=lightblue]
	140380010310288 -> 140380010162352
	140380010162352 [label=AccumulateGrad]
	140380010162304 -> 140380010162256
	140380010307728 [label="encoder.blocks.0.blocks.0.blocks.4.bn.bias
 (256)" fillcolor=lightblue]
	140380010307728 -> 140380010162304
	140380010162304 [label=AccumulateGrad]
	140380010162208 -> 140380010160816
	140380010162208 [label=CudnnBatchNormBackward0]
	140380010162976 -> 140380010162208
	140380010162976 [label=CudnnConvolutionBackward0]
	140380010163552 -> 140380010162976
	140380010163408 -> 140380010162976
	140380004116256 [label="encoder.blocks.0.blocks.0.shortcut.conv.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140380004116256 -> 140380010163408
	140380010163408 [label=AccumulateGrad]
	140380010162496 -> 140380010162208
	140380004115536 [label="encoder.blocks.0.blocks.0.shortcut.bn.weight
 (256)" fillcolor=lightblue]
	140380004115536 -> 140380010162496
	140380010162496 [label=AccumulateGrad]
	140380010162448 -> 140380010162208
	140380004118336 [label="encoder.blocks.0.blocks.0.shortcut.bn.bias
 (256)" fillcolor=lightblue]
	140380004118336 -> 140380010162448
	140380010162448 [label=AccumulateGrad]
	140380010162160 -> 140380010161872
	140380010310928 [label="encoder.blocks.0.blocks.1.blocks.0.conv.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140380010310928 -> 140380010162160
	140380010162160 [label=AccumulateGrad]
	140380010161728 -> 140380010161824
	140380010309648 [label="encoder.blocks.0.blocks.1.blocks.0.bn.weight
 (64)" fillcolor=lightblue]
	140380010309648 -> 140380010161728
	140380010161728 [label=AccumulateGrad]
	140380010161968 -> 140380010161824
	140380010309728 [label="encoder.blocks.0.blocks.1.blocks.0.bn.bias
 (64)" fillcolor=lightblue]
	140380010309728 -> 140380010161968
	140380010161968 [label=AccumulateGrad]
	140380010161632 -> 140380010161392
	140380010310368 [label="encoder.blocks.0.blocks.1.blocks.2.conv.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140380010310368 -> 140380010161632
	140380010161632 [label=AccumulateGrad]
	140380010161248 -> 140380010161344
	140380004040928 [label="encoder.blocks.0.blocks.1.blocks.2.bn.weight
 (64)" fillcolor=lightblue]
	140380004040928 -> 140380010161248
	140380010161248 [label=AccumulateGrad]
	140380010161488 -> 140380010161344
	140380010308928 [label="encoder.blocks.0.blocks.1.blocks.2.bn.bias
 (64)" fillcolor=lightblue]
	140380010308928 -> 140380010161488
	140380010161488 [label=AccumulateGrad]
	140380010161152 -> 140380010161008
	140380010310688 [label="encoder.blocks.0.blocks.1.blocks.4.conv.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140380010310688 -> 140380010161152
	140380010161152 [label=AccumulateGrad]
	140380010160960 -> 140380010160864
	140380010311408 [label="encoder.blocks.0.blocks.1.blocks.4.bn.weight
 (256)" fillcolor=lightblue]
	140380010311408 -> 140380010160960
	140380010160960 [label=AccumulateGrad]
	140380010160912 -> 140380010160864
	140380010311328 [label="encoder.blocks.0.blocks.1.blocks.4.bn.bias
 (256)" fillcolor=lightblue]
	140380010311328 -> 140380010160912
	140380010160912 [label=AccumulateGrad]
	140380010160816 -> 140380010201920
	140380010160768 -> 140380010160480
	140380010973760 [label="encoder.blocks.0.blocks.2.blocks.0.conv.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140380010973760 -> 140380010160768
	140380010160768 [label=AccumulateGrad]
	140380010160336 -> 140380010160432
	140380010972320 [label="encoder.blocks.0.blocks.2.blocks.0.bn.weight
 (64)" fillcolor=lightblue]
	140380010972320 -> 140380010160336
	140380010160336 [label=AccumulateGrad]
	140380010160576 -> 140380010160432
	140380010972560 [label="encoder.blocks.0.blocks.2.blocks.0.bn.bias
 (64)" fillcolor=lightblue]
	140380010972560 -> 140380010160576
	140380010160576 [label=AccumulateGrad]
	140380010160240 -> 140380010201344
	140380010974320 [label="encoder.blocks.0.blocks.2.blocks.2.conv.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140380010974320 -> 140380010160240
	140380010160240 [label=AccumulateGrad]
	140380010201488 -> 140380010201392
	140380010971840 [label="encoder.blocks.0.blocks.2.blocks.2.bn.weight
 (64)" fillcolor=lightblue]
	140380010971840 -> 140380010201488
	140380010201488 [label=AccumulateGrad]
	140380010201200 -> 140380010201392
	140380010971760 [label="encoder.blocks.0.blocks.2.blocks.2.bn.bias
 (64)" fillcolor=lightblue]
	140380010971760 -> 140380010201200
	140380010201200 [label=AccumulateGrad]
	140380010201584 -> 140380010201728
	140380010972800 [label="encoder.blocks.0.blocks.2.blocks.4.conv.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140380010972800 -> 140380010201584
	140380010201584 [label=AccumulateGrad]
	140380010201776 -> 140380010201872
	140380010973040 [label="encoder.blocks.0.blocks.2.blocks.4.bn.weight
 (256)" fillcolor=lightblue]
	140380010973040 -> 140380010201776
	140380010201776 [label=AccumulateGrad]
	140380010201824 -> 140380010201872
	140380010973120 [label="encoder.blocks.0.blocks.2.blocks.4.bn.bias
 (256)" fillcolor=lightblue]
	140380010973120 -> 140380010201824
	140380010201824 [label=AccumulateGrad]
	140380010201920 -> 140380010202016
	140380010201680 -> 140380010202304
	140380010972000 [label="encoder.blocks.1.blocks.0.blocks.0.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	140380010972000 -> 140380010201680
	140380010201680 [label=AccumulateGrad]
	140380010202064 -> 140380010202352
	140380010972720 [label="encoder.blocks.1.blocks.0.blocks.0.bn.weight
 (128)" fillcolor=lightblue]
	140380010972720 -> 140380010202064
	140380010202064 [label=AccumulateGrad]
	140380010202208 -> 140380010202352
	140380010971440 [label="encoder.blocks.1.blocks.0.blocks.0.bn.bias
 (128)" fillcolor=lightblue]
	140380010971440 -> 140380010202208
	140380010202208 [label=AccumulateGrad]
	140380010202544 -> 140380010202784
	140380010974400 [label="encoder.blocks.1.blocks.0.blocks.2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140380010974400 -> 140380010202544
	140380010202544 [label=AccumulateGrad]
	140380010202928 -> 140380010202448
	140380010974560 [label="encoder.blocks.1.blocks.0.blocks.2.bn.weight
 (128)" fillcolor=lightblue]
	140380010974560 -> 140380010202928
	140380010202928 [label=AccumulateGrad]
	140380010202688 -> 140380010202448
	140380010974960 [label="encoder.blocks.1.blocks.0.blocks.2.bn.bias
 (128)" fillcolor=lightblue]
	140380010974960 -> 140380010202688
	140380010202688 [label=AccumulateGrad]
	140380010203024 -> 140380010203168
	140380010972240 [label="encoder.blocks.1.blocks.0.blocks.4.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140380010972240 -> 140380010203024
	140380010203024 [label=AccumulateGrad]
	140380010202832 -> 140380010203312
	140380010973360 [label="encoder.blocks.1.blocks.0.blocks.4.bn.weight
 (512)" fillcolor=lightblue]
	140380010973360 -> 140380010202832
	140380010202832 [label=AccumulateGrad]
	140380010203264 -> 140380010203312
	140380146949792 [label="encoder.blocks.1.blocks.0.blocks.4.bn.bias
 (512)" fillcolor=lightblue]
	140380146949792 -> 140380010203264
	140380010203264 [label=AccumulateGrad]
	140380010203360 -> 140380010204368
	140380010203360 [label=CudnnBatchNormBackward0]
	140380010202592 -> 140380010203360
	140380010202592 [label=CudnnConvolutionBackward0]
	140380010202016 -> 140380010202592
	140380010202160 -> 140380010202592
	140380010973840 [label="encoder.blocks.1.blocks.0.shortcut.conv.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140380010973840 -> 140380010202160
	140380010202160 [label=AccumulateGrad]
	140380010203072 -> 140380010203360
	140380010972080 [label="encoder.blocks.1.blocks.0.shortcut.bn.weight
 (512)" fillcolor=lightblue]
	140380010972080 -> 140380010203072
	140380010203072 [label=AccumulateGrad]
	140380010203120 -> 140380010203360
	140380010973600 [label="encoder.blocks.1.blocks.0.shortcut.bn.bias
 (512)" fillcolor=lightblue]
	140380010973600 -> 140380010203120
	140380010203120 [label=AccumulateGrad]
	140380010203408 -> 140380010203696
	140380140979040 [label="encoder.blocks.1.blocks.1.blocks.0.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140380140979040 -> 140380010203408
	140380010203408 [label=AccumulateGrad]
	140380010203840 -> 140380010203744
	140380140978400 [label="encoder.blocks.1.blocks.1.blocks.0.bn.weight
 (128)" fillcolor=lightblue]
	140380140978400 -> 140380010203840
	140380010203840 [label=AccumulateGrad]
	140380010203216 -> 140380010203744
	140380140979280 [label="encoder.blocks.1.blocks.1.blocks.0.bn.bias
 (128)" fillcolor=lightblue]
	140380140979280 -> 140380010203216
	140380010203216 [label=AccumulateGrad]
	140380010203936 -> 140380010204176
	140380150802608 [label="encoder.blocks.1.blocks.1.blocks.2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140380150802608 -> 140380010203936
	140380010203936 [label=AccumulateGrad]
	140380010204320 -> 140380010204224
	140380150802288 [label="encoder.blocks.1.blocks.1.blocks.2.bn.weight
 (128)" fillcolor=lightblue]
	140380150802288 -> 140380010204320
	140380010204320 [label=AccumulateGrad]
	140380010204080 -> 140380010204224
	140380150802048 [label="encoder.blocks.1.blocks.1.blocks.2.bn.bias
 (128)" fillcolor=lightblue]
	140380150802048 -> 140380010204080
	140380010204080 [label=AccumulateGrad]
	140380010204560 -> 140380010204704
	140380032629472 [label="encoder.blocks.1.blocks.1.blocks.4.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140380032629472 -> 140380010204560
	140380010204560 [label=AccumulateGrad]
	140380010204752 -> 140380010204848
	140380032627152 [label="encoder.blocks.1.blocks.1.blocks.4.bn.weight
 (512)" fillcolor=lightblue]
	140380032627152 -> 140380010204752
	140380010204752 [label=AccumulateGrad]
	140380010204800 -> 140380010204848
	140380032627712 [label="encoder.blocks.1.blocks.1.blocks.4.bn.bias
 (512)" fillcolor=lightblue]
	140380032627712 -> 140380010204800
	140380010204800 [label=AccumulateGrad]
	140380010204368 -> 140380010175552
	140380010204416 -> 140380010205136
	140380032630112 [label="encoder.blocks.1.blocks.2.blocks.0.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140380032630112 -> 140380010204416
	140380010204416 [label=AccumulateGrad]
	140380010204944 -> 140380010176464
	140380032628432 [label="encoder.blocks.1.blocks.2.blocks.0.bn.weight
 (128)" fillcolor=lightblue]
	140380032628432 -> 140380010204944
	140380010204944 [label=AccumulateGrad]
	140380010205040 -> 140380010176464
	140380032627872 [label="encoder.blocks.1.blocks.2.blocks.0.bn.bias
 (128)" fillcolor=lightblue]
	140380032627872 -> 140380010205040
	140380010205040 [label=AccumulateGrad]
	140380010176368 -> 140380010176128
	140380032630032 [label="encoder.blocks.1.blocks.2.blocks.2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140380032630032 -> 140380010176368
	140380010176368 [label=AccumulateGrad]
	140380010175984 -> 140380010176080
	140380032630512 [label="encoder.blocks.1.blocks.2.blocks.2.bn.weight
 (128)" fillcolor=lightblue]
	140380032630512 -> 140380010175984
	140380010175984 [label=AccumulateGrad]
	140380010176224 -> 140380010176080
	140380032627232 [label="encoder.blocks.1.blocks.2.blocks.2.bn.bias
 (128)" fillcolor=lightblue]
	140380032627232 -> 140380010176224
	140380010176224 [label=AccumulateGrad]
	140380010175888 -> 140380010175744
	140380032627072 [label="encoder.blocks.1.blocks.2.blocks.4.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140380032627072 -> 140380010175888
	140380010175888 [label=AccumulateGrad]
	140380010175696 -> 140380010175600
	140380032629632 [label="encoder.blocks.1.blocks.2.blocks.4.bn.weight
 (512)" fillcolor=lightblue]
	140380032629632 -> 140380010175696
	140380010175696 [label=AccumulateGrad]
	140380010175648 -> 140380010175600
	140380032628112 [label="encoder.blocks.1.blocks.2.blocks.4.bn.bias
 (512)" fillcolor=lightblue]
	140380032628112 -> 140380010175648
	140380010175648 [label=AccumulateGrad]
	140380010175552 -> 140380010174160
	140380010175504 -> 140380010175216
	140380032629952 [label="encoder.blocks.1.blocks.3.blocks.0.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140380032629952 -> 140380010175504
	140380010175504 [label=AccumulateGrad]
	140380010175072 -> 140380010175168
	140380032628912 [label="encoder.blocks.1.blocks.3.blocks.0.bn.weight
 (128)" fillcolor=lightblue]
	140380032628912 -> 140380010175072
	140380010175072 [label=AccumulateGrad]
	140380010175312 -> 140380010175168
	140380032628352 [label="encoder.blocks.1.blocks.3.blocks.0.bn.bias
 (128)" fillcolor=lightblue]
	140380032628352 -> 140380010175312
	140380010175312 [label=AccumulateGrad]
	140380010174976 -> 140380010174736
	140380032627792 [label="encoder.blocks.1.blocks.3.blocks.2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140380032627792 -> 140380010174976
	140380010174976 [label=AccumulateGrad]
	140380010174592 -> 140380010174688
	140380010411968 [label="encoder.blocks.1.blocks.3.blocks.2.bn.weight
 (128)" fillcolor=lightblue]
	140380010411968 -> 140380010174592
	140380010174592 [label=AccumulateGrad]
	140380010174832 -> 140380010174688
	140380010410048 [label="encoder.blocks.1.blocks.3.blocks.2.bn.bias
 (128)" fillcolor=lightblue]
	140380010410048 -> 140380010174832
	140380010174832 [label=AccumulateGrad]
	140380010174496 -> 140380010174352
	140380010410528 [label="encoder.blocks.1.blocks.3.blocks.4.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140380010410528 -> 140380010174496
	140380010174496 [label=AccumulateGrad]
	140380010174304 -> 140380010174208
	140380010410608 [label="encoder.blocks.1.blocks.3.blocks.4.bn.weight
 (512)" fillcolor=lightblue]
	140380010410608 -> 140380010174304
	140380010174304 [label=AccumulateGrad]
	140380010174256 -> 140380010174208
	140380010410688 [label="encoder.blocks.1.blocks.3.blocks.4.bn.bias
 (512)" fillcolor=lightblue]
	140380010410688 -> 140380010174256
	140380010174256 [label=AccumulateGrad]
	140380010174160 -> 140380010172768
	140380010174112 -> 140380010173824
	140380010411088 [label="encoder.blocks.1.blocks.4.blocks.0.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140380010411088 -> 140380010174112
	140380010174112 [label=AccumulateGrad]
	140380010173680 -> 140380010173776
	140380010411168 [label="encoder.blocks.1.blocks.4.blocks.0.bn.weight
 (128)" fillcolor=lightblue]
	140380010411168 -> 140380010173680
	140380010173680 [label=AccumulateGrad]
	140380010173920 -> 140380010173776
	140380010410448 [label="encoder.blocks.1.blocks.4.blocks.0.bn.bias
 (128)" fillcolor=lightblue]
	140380010410448 -> 140380010173920
	140380010173920 [label=AccumulateGrad]
	140380010173584 -> 140380010173344
	140380010411648 [label="encoder.blocks.1.blocks.4.blocks.2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140380010411648 -> 140380010173584
	140380010173584 [label=AccumulateGrad]
	140380010173200 -> 140380010173296
	140380010411728 [label="encoder.blocks.1.blocks.4.blocks.2.bn.weight
 (128)" fillcolor=lightblue]
	140380010411728 -> 140380010173200
	140380010173200 [label=AccumulateGrad]
	140380010173440 -> 140380010173296
	140380010411808 [label="encoder.blocks.1.blocks.4.blocks.2.bn.bias
 (128)" fillcolor=lightblue]
	140380010411808 -> 140380010173440
	140380010173440 [label=AccumulateGrad]
	140380010173104 -> 140380010172960
	140380009560000 [label="encoder.blocks.1.blocks.4.blocks.4.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140380009560000 -> 140380010173104
	140380010173104 [label=AccumulateGrad]
	140380010172912 -> 140380010172816
	140380009559200 [label="encoder.blocks.1.blocks.4.blocks.4.bn.weight
 (512)" fillcolor=lightblue]
	140380009559200 -> 140380010172912
	140380010172912 [label=AccumulateGrad]
	140380010172864 -> 140380010172816
	140380009558320 [label="encoder.blocks.1.blocks.4.blocks.4.bn.bias
 (512)" fillcolor=lightblue]
	140380009558320 -> 140380010172864
	140380010172864 [label=AccumulateGrad]
	140380010172768 -> 140380009761712
	140380010172720 -> 140380009762624
	140380009561760 [label="encoder.blocks.1.blocks.5.blocks.0.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140380009561760 -> 140380010172720
	140380010172720 [label=AccumulateGrad]
	140380010172480 -> 140380009762720
	140380009560800 [label="encoder.blocks.1.blocks.5.blocks.0.bn.weight
 (128)" fillcolor=lightblue]
	140380009560800 -> 140380010172480
	140380010172480 [label=AccumulateGrad]
	140380010172528 -> 140380009762720
	140380009558240 [label="encoder.blocks.1.blocks.5.blocks.0.bn.bias
 (128)" fillcolor=lightblue]
	140380009558240 -> 140380010172528
	140380010172528 [label=AccumulateGrad]
	140380009762528 -> 140380009762288
	140380009561280 [label="encoder.blocks.1.blocks.5.blocks.2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140380009561280 -> 140380009762528
	140380009762528 [label=AccumulateGrad]
	140380009762144 -> 140380009762240
	140380009559360 [label="encoder.blocks.1.blocks.5.blocks.2.bn.weight
 (128)" fillcolor=lightblue]
	140380009559360 -> 140380009762144
	140380009762144 [label=AccumulateGrad]
	140380009762384 -> 140380009762240
	140380009559120 [label="encoder.blocks.1.blocks.5.blocks.2.bn.bias
 (128)" fillcolor=lightblue]
	140380009559120 -> 140380009762384
	140380009762384 [label=AccumulateGrad]
	140380009762048 -> 140380009761904
	140380009560400 [label="encoder.blocks.1.blocks.5.blocks.4.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140380009560400 -> 140380009762048
	140380009762048 [label=AccumulateGrad]
	140380009761856 -> 140380009761760
	140380009558560 [label="encoder.blocks.1.blocks.5.blocks.4.bn.weight
 (512)" fillcolor=lightblue]
	140380009558560 -> 140380009761856
	140380009761856 [label=AccumulateGrad]
	140380009761808 -> 140380009761760
	140380009558480 [label="encoder.blocks.1.blocks.5.blocks.4.bn.bias
 (512)" fillcolor=lightblue]
	140380009558480 -> 140380009761808
	140380009761808 [label=AccumulateGrad]
	140380009761712 -> 140380009760320
	140380009761664 -> 140380009761376
	140380009559280 [label="encoder.blocks.1.blocks.6.blocks.0.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140380009559280 -> 140380009761664
	140380009761664 [label=AccumulateGrad]
	140380009761232 -> 140380009761328
	140380009559760 [label="encoder.blocks.1.blocks.6.blocks.0.bn.weight
 (128)" fillcolor=lightblue]
	140380009559760 -> 140380009761232
	140380009761232 [label=AccumulateGrad]
	140380009761472 -> 140380009761328
	140380009559520 [label="encoder.blocks.1.blocks.6.blocks.0.bn.bias
 (128)" fillcolor=lightblue]
	140380009559520 -> 140380009761472
	140380009761472 [label=AccumulateGrad]
	140380009761136 -> 140380009760896
	140380009561040 [label="encoder.blocks.1.blocks.6.blocks.2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140380009561040 -> 140380009761136
	140380009761136 [label=AccumulateGrad]
	140380009760752 -> 140380009760848
	140380009560640 [label="encoder.blocks.1.blocks.6.blocks.2.bn.weight
 (128)" fillcolor=lightblue]
	140380009560640 -> 140380009760752
	140380009760752 [label=AccumulateGrad]
	140380009760992 -> 140380009760848
	140380009558080 [label="encoder.blocks.1.blocks.6.blocks.2.bn.bias
 (128)" fillcolor=lightblue]
	140380009558080 -> 140380009760992
	140380009760992 [label=AccumulateGrad]
	140380009760656 -> 140380009760512
	140380009560240 [label="encoder.blocks.1.blocks.6.blocks.4.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140380009560240 -> 140380009760656
	140380009760656 [label=AccumulateGrad]
	140380009760464 -> 140380009760368
	140380009560560 [label="encoder.blocks.1.blocks.6.blocks.4.bn.weight
 (512)" fillcolor=lightblue]
	140380009560560 -> 140380009760464
	140380009760464 [label=AccumulateGrad]
	140380009760416 -> 140380009760368
	140380009560880 [label="encoder.blocks.1.blocks.6.blocks.4.bn.bias
 (512)" fillcolor=lightblue]
	140380009560880 -> 140380009760416
	140380009760416 [label=AccumulateGrad]
	140380009760320 -> 140380009758928
	140380009760272 -> 140380009759984
	140380287890992 [label="encoder.blocks.1.blocks.7.blocks.0.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140380287890992 -> 140380009760272
	140380009760272 [label=AccumulateGrad]
	140380009759840 -> 140380009759936
	140380285588000 [label="encoder.blocks.1.blocks.7.blocks.0.bn.weight
 (128)" fillcolor=lightblue]
	140380285588000 -> 140380009759840
	140380009759840 [label=AccumulateGrad]
	140380009760080 -> 140380009759936
	140380286574816 [label="encoder.blocks.1.blocks.7.blocks.0.bn.bias
 (128)" fillcolor=lightblue]
	140380286574816 -> 140380009760080
	140380009760080 [label=AccumulateGrad]
	140380009759744 -> 140380009759504
	140380287799760 [label="encoder.blocks.1.blocks.7.blocks.2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140380287799760 -> 140380009759744
	140380009759744 [label=AccumulateGrad]
	140380009759360 -> 140380009759456
	140380287800960 [label="encoder.blocks.1.blocks.7.blocks.2.bn.weight
 (128)" fillcolor=lightblue]
	140380287800960 -> 140380009759360
	140380009759360 [label=AccumulateGrad]
	140380009759600 -> 140380009759456
	140380287680240 [label="encoder.blocks.1.blocks.7.blocks.2.bn.bias
 (128)" fillcolor=lightblue]
	140380287680240 -> 140380009759600
	140380009759600 [label=AccumulateGrad]
	140380009759264 -> 140380009759120
	140380144823808 [label="encoder.blocks.1.blocks.7.blocks.4.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140380144823808 -> 140380009759264
	140380009759264 [label=AccumulateGrad]
	140380009759072 -> 140380009758976
	140380144823168 [label="encoder.blocks.1.blocks.7.blocks.4.bn.weight
 (512)" fillcolor=lightblue]
	140380144823168 -> 140380009759072
	140380009759072 [label=AccumulateGrad]
	140380009759024 -> 140380009758976
	140380144823248 [label="encoder.blocks.1.blocks.7.blocks.4.bn.bias
 (512)" fillcolor=lightblue]
	140380144823248 -> 140380009759024
	140380009759024 [label=AccumulateGrad]
	140380009758928 -> 140380009758672
	140380009758832 -> 140380009758480
	140380144821728 [label="encoder.blocks.2.blocks.0.blocks.0.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140380144821728 -> 140380009758832
	140380009758832 [label=AccumulateGrad]
	140380009758336 -> 140380009758432
	140380144821648 [label="encoder.blocks.2.blocks.0.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380144821648 -> 140380009758336
	140380009758336 [label=AccumulateGrad]
	140380009758576 -> 140380009758432
	140380144821328 [label="encoder.blocks.2.blocks.0.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380144821328 -> 140380009758576
	140380009758576 [label=AccumulateGrad]
	140380009758240 -> 140380009758000
	140380144820768 [label="encoder.blocks.2.blocks.0.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380144820768 -> 140380009758240
	140380009758240 [label=AccumulateGrad]
	140380009757856 -> 140380009757952
	140380144820448 [label="encoder.blocks.2.blocks.0.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380144820448 -> 140380009757856
	140380009757856 [label=AccumulateGrad]
	140380009758096 -> 140380009757952
	140380144820368 [label="encoder.blocks.2.blocks.0.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380144820368 -> 140380009758096
	140380009758096 [label=AccumulateGrad]
	140380009757760 -> 140380009757616
	140380144820608 [label="encoder.blocks.2.blocks.0.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380144820608 -> 140380009757760
	140380009757760 [label=AccumulateGrad]
	140380009757568 -> 140380009757472
	140380144821488 [label="encoder.blocks.2.blocks.0.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380144821488 -> 140380009757568
	140380009757568 [label=AccumulateGrad]
	140380009757520 -> 140380009757472
	140380144821248 [label="encoder.blocks.2.blocks.0.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380144821248 -> 140380009757520
	140380009757520 [label=AccumulateGrad]
	140380009757424 -> 140380009756032
	140380009757424 [label=CudnnBatchNormBackward0]
	140380009758192 -> 140380009757424
	140380009758192 [label=CudnnConvolutionBackward0]
	140380009758672 -> 140380009758192
	140380009758384 -> 140380009758192
	140380144822928 [label="encoder.blocks.2.blocks.0.shortcut.conv.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140380144822928 -> 140380009758384
	140380009758384 [label=AccumulateGrad]
	140380009757712 -> 140380009757424
	140380144822608 [label="encoder.blocks.2.blocks.0.shortcut.bn.weight
 (1024)" fillcolor=lightblue]
	140380144822608 -> 140380009757712
	140380009757712 [label=AccumulateGrad]
	140380009757664 -> 140380009757424
	140380144822688 [label="encoder.blocks.2.blocks.0.shortcut.bn.bias
 (1024)" fillcolor=lightblue]
	140380144822688 -> 140380009757664
	140380009757664 [label=AccumulateGrad]
	140380009757376 -> 140380009757088
	140380144357920 [label="encoder.blocks.2.blocks.1.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380144357920 -> 140380009757376
	140380009757376 [label=AccumulateGrad]
	140380009756944 -> 140380009757040
	140380144360480 [label="encoder.blocks.2.blocks.1.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380144360480 -> 140380009756944
	140380009756944 [label=AccumulateGrad]
	140380009757184 -> 140380009757040
	140380144360080 [label="encoder.blocks.2.blocks.1.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380144360080 -> 140380009757184
	140380009757184 [label=AccumulateGrad]
	140380009756848 -> 140380009756608
	140380144359920 [label="encoder.blocks.2.blocks.1.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380144359920 -> 140380009756848
	140380009756848 [label=AccumulateGrad]
	140380009756464 -> 140380009756560
	140380144360800 [label="encoder.blocks.2.blocks.1.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380144360800 -> 140380009756464
	140380009756464 [label=AccumulateGrad]
	140380009756704 -> 140380009756560
	140380144358880 [label="encoder.blocks.2.blocks.1.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380144358880 -> 140380009756704
	140380009756704 [label=AccumulateGrad]
	140380009756368 -> 140380009756224
	140380286510480 [label="encoder.blocks.2.blocks.1.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380286510480 -> 140380009756368
	140380009756368 [label=AccumulateGrad]
	140380009756176 -> 140380009756080
	140380286511600 [label="encoder.blocks.2.blocks.1.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380286511600 -> 140380009756176
	140380009756176 [label=AccumulateGrad]
	140380009756128 -> 140380009756080
	140380285410736 [label="encoder.blocks.2.blocks.1.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380285410736 -> 140380009756128
	140380009756128 [label=AccumulateGrad]
	140380009756032 -> 140380009774912
	140380009755984 -> 140380009755696
	140380134317728 [label="encoder.blocks.2.blocks.2.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380134317728 -> 140380009755984
	140380009755984 [label=AccumulateGrad]
	140380009755552 -> 140380009755648
	140380134317648 [label="encoder.blocks.2.blocks.2.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380134317648 -> 140380009755552
	140380009755552 [label=AccumulateGrad]
	140380009755792 -> 140380009755648
	140380134314128 [label="encoder.blocks.2.blocks.2.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380134314128 -> 140380009755792
	140380009755792 [label=AccumulateGrad]
	140380009755456 -> 140380009755216
	140380134315888 [label="encoder.blocks.2.blocks.2.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380134315888 -> 140380009755456
	140380009755456 [label=AccumulateGrad]
	140380009755072 -> 140380009755168
	140380134317968 [label="encoder.blocks.2.blocks.2.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380134317968 -> 140380009755072
	140380009755072 [label=AccumulateGrad]
	140380009755312 -> 140380009755168
	140380134317888 [label="encoder.blocks.2.blocks.2.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380134317888 -> 140380009755312
	140380009755312 [label=AccumulateGrad]
	140380009754976 -> 140380009754832
	140380134314928 [label="encoder.blocks.2.blocks.2.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380134314928 -> 140380009754976
	140380009754976 [label=AccumulateGrad]
	140380009754784 -> 140380009775056
	140380134314848 [label="encoder.blocks.2.blocks.2.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380134314848 -> 140380009754784
	140380009754784 [label=AccumulateGrad]
	140380009754736 -> 140380009775056
	140380134314768 [label="encoder.blocks.2.blocks.2.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380134314768 -> 140380009754736
	140380009754736 [label=AccumulateGrad]
	140380009774912 -> 140380009773664
	140380009775008 -> 140380009774720
	140380134316688 [label="encoder.blocks.2.blocks.3.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380134316688 -> 140380009775008
	140380009775008 [label=AccumulateGrad]
	140380009774576 -> 140380009774672
	140380134317408 [label="encoder.blocks.2.blocks.3.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380134317408 -> 140380009774576
	140380009774576 [label=AccumulateGrad]
	140380009774816 -> 140380009774672
	140380134317248 [label="encoder.blocks.2.blocks.3.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380134317248 -> 140380009774816
	140380009774816 [label=AccumulateGrad]
	140380009774480 -> 140380009774240
	140380134315088 [label="encoder.blocks.2.blocks.3.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380134315088 -> 140380009774480
	140380009774480 [label=AccumulateGrad]
	140380009774096 -> 140380009774192
	140380134315008 [label="encoder.blocks.2.blocks.3.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380134315008 -> 140380009774096
	140380009774096 [label=AccumulateGrad]
	140380009774336 -> 140380009774192
	140380134316528 [label="encoder.blocks.2.blocks.3.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380134316528 -> 140380009774336
	140380009774336 [label=AccumulateGrad]
	140380009774000 -> 140380009773856
	140380134314608 [label="encoder.blocks.2.blocks.3.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380134314608 -> 140380009774000
	140380009774000 [label=AccumulateGrad]
	140380009773808 -> 140380009773712
	140380134314208 [label="encoder.blocks.2.blocks.3.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380134314208 -> 140380009773808
	140380009773808 [label=AccumulateGrad]
	140380009773760 -> 140380009773712
	140380134317328 [label="encoder.blocks.2.blocks.3.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380134317328 -> 140380009773760
	140380009773760 [label=AccumulateGrad]
	140380009773664 -> 140380009772272
	140380009773616 -> 140380009773328
	140380134315488 [label="encoder.blocks.2.blocks.4.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380134315488 -> 140380009773616
	140380009773616 [label=AccumulateGrad]
	140380009773184 -> 140380009773280
	140380134317808 [label="encoder.blocks.2.blocks.4.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380134317808 -> 140380009773184
	140380009773184 [label=AccumulateGrad]
	140380009773424 -> 140380009773280
	140380134317568 [label="encoder.blocks.2.blocks.4.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380134317568 -> 140380009773424
	140380009773424 [label=AccumulateGrad]
	140380009773088 -> 140380009772848
	140380137246864 [label="encoder.blocks.2.blocks.4.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380137246864 -> 140380009773088
	140380009773088 [label=AccumulateGrad]
	140380009772704 -> 140380009772800
	140380137246784 [label="encoder.blocks.2.blocks.4.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380137246784 -> 140380009772704
	140380009772704 [label=AccumulateGrad]
	140380009772944 -> 140380009772800
	140380137247264 [label="encoder.blocks.2.blocks.4.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380137247264 -> 140380009772944
	140380009772944 [label=AccumulateGrad]
	140380009772608 -> 140380009772464
	140380137247584 [label="encoder.blocks.2.blocks.4.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380137247584 -> 140380009772608
	140380009772608 [label=AccumulateGrad]
	140380009772416 -> 140380009772320
	140380137248544 [label="encoder.blocks.2.blocks.4.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380137248544 -> 140380009772416
	140380009772416 [label=AccumulateGrad]
	140380009772368 -> 140380009772320
	140380137248144 [label="encoder.blocks.2.blocks.4.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380137248144 -> 140380009772368
	140380009772368 [label=AccumulateGrad]
	140380009772272 -> 140380009615168
	140380009772224 -> 140380009771936
	140380137248384 [label="encoder.blocks.2.blocks.5.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380137248384 -> 140380009772224
	140380009772224 [label=AccumulateGrad]
	140380009771792 -> 140380009771888
	140380137248304 [label="encoder.blocks.2.blocks.5.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380137248304 -> 140380009771792
	140380009771792 [label=AccumulateGrad]
	140380009772032 -> 140380009771888
	140380137248064 [label="encoder.blocks.2.blocks.5.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380137248064 -> 140380009772032
	140380009772032 [label=AccumulateGrad]
	140380009771696 -> 140380009771456
	140380137249824 [label="encoder.blocks.2.blocks.5.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380137249824 -> 140380009771696
	140380009771696 [label=AccumulateGrad]
	140380009771312 -> 140380009771408
	140380137249184 [label="encoder.blocks.2.blocks.5.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380137249184 -> 140380009771312
	140380009771312 [label=AccumulateGrad]
	140380009771552 -> 140380009771408
	140380137248464 [label="encoder.blocks.2.blocks.5.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380137248464 -> 140380009771552
	140380009771552 [label=AccumulateGrad]
	140380009771216 -> 140380009615312
	140380143024864 [label="encoder.blocks.2.blocks.5.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380143024864 -> 140380009771216
	140380009771216 [label=AccumulateGrad]
	140380009615264 -> 140380009615216
	140380143024544 [label="encoder.blocks.2.blocks.5.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380143024544 -> 140380009615264
	140380009615264 [label=AccumulateGrad]
	140380009771072 -> 140380009615216
	140380143024704 [label="encoder.blocks.2.blocks.5.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380143024704 -> 140380009771072
	140380009771072 [label=AccumulateGrad]
	140380009615168 -> 140380009613776
	140380009615120 -> 140380009614832
	140380143022944 [label="encoder.blocks.2.blocks.6.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380143022944 -> 140380009615120
	140380009615120 [label=AccumulateGrad]
	140380009614688 -> 140380009614784
	140380143023184 [label="encoder.blocks.2.blocks.6.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380143023184 -> 140380009614688
	140380009614688 [label=AccumulateGrad]
	140380009614928 -> 140380009614784
	140380143022224 [label="encoder.blocks.2.blocks.6.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380143022224 -> 140380009614928
	140380009614928 [label=AccumulateGrad]
	140380009614592 -> 140380009614352
	140380143025664 [label="encoder.blocks.2.blocks.6.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380143025664 -> 140380009614592
	140380009614592 [label=AccumulateGrad]
	140380009614208 -> 140380009614304
	140380143025584 [label="encoder.blocks.2.blocks.6.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380143025584 -> 140380009614208
	140380009614208 [label=AccumulateGrad]
	140380009614448 -> 140380009614304
	140380143025504 [label="encoder.blocks.2.blocks.6.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380143025504 -> 140380009614448
	140380009614448 [label=AccumulateGrad]
	140380009614112 -> 140380009613968
	140380143023824 [label="encoder.blocks.2.blocks.6.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380143023824 -> 140380009614112
	140380009614112 [label=AccumulateGrad]
	140380009613920 -> 140380009613824
	140380143024624 [label="encoder.blocks.2.blocks.6.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380143024624 -> 140380009613920
	140380009613920 [label=AccumulateGrad]
	140380009613872 -> 140380009613824
	140380143024464 [label="encoder.blocks.2.blocks.6.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380143024464 -> 140380009613872
	140380009613872 [label=AccumulateGrad]
	140380009613776 -> 140380009612384
	140380009613728 -> 140380009613440
	140380285731760 [label="encoder.blocks.2.blocks.7.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380285731760 -> 140380009613728
	140380009613728 [label=AccumulateGrad]
	140380009613296 -> 140380009613392
	140380285730960 [label="encoder.blocks.2.blocks.7.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380285730960 -> 140380009613296
	140380009613296 [label=AccumulateGrad]
	140380009613536 -> 140380009613392
	140380285730880 [label="encoder.blocks.2.blocks.7.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380285730880 -> 140380009613536
	140380009613536 [label=AccumulateGrad]
	140380009613200 -> 140380009612960
	140380142959968 [label="encoder.blocks.2.blocks.7.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380142959968 -> 140380009613200
	140380009613200 [label=AccumulateGrad]
	140380009612816 -> 140380009612912
	140380142959888 [label="encoder.blocks.2.blocks.7.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380142959888 -> 140380009612816
	140380009612816 [label=AccumulateGrad]
	140380009613056 -> 140380009612912
	140380142959568 [label="encoder.blocks.2.blocks.7.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380142959568 -> 140380009613056
	140380009613056 [label=AccumulateGrad]
	140380009612720 -> 140380009612576
	140380142959008 [label="encoder.blocks.2.blocks.7.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380142959008 -> 140380009612720
	140380009612720 [label=AccumulateGrad]
	140380009612528 -> 140380009612432
	140380142958688 [label="encoder.blocks.2.blocks.7.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380142958688 -> 140380009612528
	140380009612528 [label=AccumulateGrad]
	140380009612480 -> 140380009612432
	140380142958608 [label="encoder.blocks.2.blocks.7.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380142958608 -> 140380009612480
	140380009612480 [label=AccumulateGrad]
	140380009612384 -> 140380009791152
	140380009612336 -> 140380009612048
	140380142957728 [label="encoder.blocks.2.blocks.8.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380142957728 -> 140380009612336
	140380009612336 [label=AccumulateGrad]
	140380009611904 -> 140380009612000
	140380142957568 [label="encoder.blocks.2.blocks.8.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380142957568 -> 140380009611904
	140380009611904 [label=AccumulateGrad]
	140380009612144 -> 140380009612000
	140380142956928 [label="encoder.blocks.2.blocks.8.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380142956928 -> 140380009612144
	140380009612144 [label=AccumulateGrad]
	140380009611808 -> 140380009611568
	140380142957168 [label="encoder.blocks.2.blocks.8.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380142957168 -> 140380009611808
	140380009611808 [label=AccumulateGrad]
	140380009611424 -> 140380009611520
	140380142957408 [label="encoder.blocks.2.blocks.8.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380142957408 -> 140380009611424
	140380009611424 [label=AccumulateGrad]
	140380009611664 -> 140380009611520
	140380142956608 [label="encoder.blocks.2.blocks.8.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380142956608 -> 140380009611664
	140380009611664 [label=AccumulateGrad]
	140380009611376 -> 140380009791344
	140380142959088 [label="encoder.blocks.2.blocks.8.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380142959088 -> 140380009611376
	140380009611376 [label=AccumulateGrad]
	140380009791296 -> 140380009791200
	140380142958848 [label="encoder.blocks.2.blocks.8.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380142958848 -> 140380009791296
	140380009791296 [label=AccumulateGrad]
	140380009791248 -> 140380009791200
	140380142959728 [label="encoder.blocks.2.blocks.8.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380142959728 -> 140380009791248
	140380009791248 [label=AccumulateGrad]
	140380009791152 -> 140380009789760
	140380009791104 -> 140380009790816
	140380141177968 [label="encoder.blocks.2.blocks.9.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380141177968 -> 140380009791104
	140380009791104 [label=AccumulateGrad]
	140380009790672 -> 140380009790768
	140380141178688 [label="encoder.blocks.2.blocks.9.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380141178688 -> 140380009790672
	140380009790672 [label=AccumulateGrad]
	140380009790912 -> 140380009790768
	140380141177808 [label="encoder.blocks.2.blocks.9.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380141177808 -> 140380009790912
	140380009790912 [label=AccumulateGrad]
	140380009790576 -> 140380009790336
	140380141982480 [label="encoder.blocks.2.blocks.9.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380141982480 -> 140380009790576
	140380009790576 [label=AccumulateGrad]
	140380009790192 -> 140380009790288
	140380141982400 [label="encoder.blocks.2.blocks.9.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380141982400 -> 140380009790192
	140380009790192 [label=AccumulateGrad]
	140380009790432 -> 140380009790288
	140380141983920 [label="encoder.blocks.2.blocks.9.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380141983920 -> 140380009790432
	140380009790432 [label=AccumulateGrad]
	140380009790096 -> 140380009789952
	140380141981920 [label="encoder.blocks.2.blocks.9.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380141981920 -> 140380009790096
	140380009790096 [label=AccumulateGrad]
	140380009789904 -> 140380009789808
	140380141981840 [label="encoder.blocks.2.blocks.9.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380141981840 -> 140380009789904
	140380009789904 [label=AccumulateGrad]
	140380009789856 -> 140380009789808
	140380141985120 [label="encoder.blocks.2.blocks.9.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380141985120 -> 140380009789856
	140380009789856 [label=AccumulateGrad]
	140380009789760 -> 140380009788368
	140380009789712 -> 140380009789424
	140380141983680 [label="encoder.blocks.2.blocks.10.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380141983680 -> 140380009789712
	140380009789712 [label=AccumulateGrad]
	140380009789280 -> 140380009789376
	140380141982960 [label="encoder.blocks.2.blocks.10.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380141982960 -> 140380009789280
	140380009789280 [label=AccumulateGrad]
	140380009789520 -> 140380009789376
	140380141982880 [label="encoder.blocks.2.blocks.10.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380141982880 -> 140380009789520
	140380009789520 [label=AccumulateGrad]
	140380009789184 -> 140380009788944
	140380141985680 [label="encoder.blocks.2.blocks.10.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380141985680 -> 140380009789184
	140380009789184 [label=AccumulateGrad]
	140380009788800 -> 140380009788896
	140380141984640 [label="encoder.blocks.2.blocks.10.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380141984640 -> 140380009788800
	140380009788800 [label=AccumulateGrad]
	140380009789040 -> 140380009788896
	140380141983280 [label="encoder.blocks.2.blocks.10.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380141983280 -> 140380009789040
	140380009789040 [label=AccumulateGrad]
	140380009788704 -> 140380009788560
	140380141983600 [label="encoder.blocks.2.blocks.10.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380141983600 -> 140380009788704
	140380009788704 [label=AccumulateGrad]
	140380009788512 -> 140380009788416
	140380141983200 [label="encoder.blocks.2.blocks.10.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380141983200 -> 140380009788512
	140380009788512 [label=AccumulateGrad]
	140380009788464 -> 140380009788416
	140380141982560 [label="encoder.blocks.2.blocks.10.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380141982560 -> 140380009788464
	140380009788464 [label=AccumulateGrad]
	140380009788368 -> 140380009868832
	140380009788320 -> 140380009788032
	140380141984880 [label="encoder.blocks.2.blocks.11.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380141984880 -> 140380009788320
	140380009788320 [label=AccumulateGrad]
	140380009787888 -> 140380009787984
	140380141984800 [label="encoder.blocks.2.blocks.11.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380141984800 -> 140380009787888
	140380009787888 [label=AccumulateGrad]
	140380009788128 -> 140380009787984
	140380141983360 [label="encoder.blocks.2.blocks.11.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380141983360 -> 140380009788128
	140380009788128 [label=AccumulateGrad]
	140380009787792 -> 140380009787552
	140380141982640 [label="encoder.blocks.2.blocks.11.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380141982640 -> 140380009787792
	140380009787792 [label=AccumulateGrad]
	140380009787456 -> 140380009869264
	140380141982080 [label="encoder.blocks.2.blocks.11.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380141982080 -> 140380009787456
	140380009787456 [label=AccumulateGrad]
	140380009787648 -> 140380009869264
	140380141982000 [label="encoder.blocks.2.blocks.11.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380141982000 -> 140380009787648
	140380009787648 [label=AccumulateGrad]
	140380009869168 -> 140380009869024
	140380134392112 [label="encoder.blocks.2.blocks.11.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380134392112 -> 140380009869168
	140380009869168 [label=AccumulateGrad]
	140380009868976 -> 140380009868880
	140380134392752 [label="encoder.blocks.2.blocks.11.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380134392752 -> 140380009868976
	140380009868976 [label=AccumulateGrad]
	140380009868928 -> 140380009868880
	140380134392672 [label="encoder.blocks.2.blocks.11.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380134392672 -> 140380009868928
	140380009868928 [label=AccumulateGrad]
	140380009868832 -> 140380009867440
	140380009868784 -> 140380009868496
	140380134395712 [label="encoder.blocks.2.blocks.12.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380134395712 -> 140380009868784
	140380009868784 [label=AccumulateGrad]
	140380009868352 -> 140380009868448
	140380134393152 [label="encoder.blocks.2.blocks.12.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380134393152 -> 140380009868352
	140380009868352 [label=AccumulateGrad]
	140380009868592 -> 140380009868448
	140380134392432 [label="encoder.blocks.2.blocks.12.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380134392432 -> 140380009868592
	140380009868592 [label=AccumulateGrad]
	140380009868256 -> 140380009868016
	140380287069376 [label="encoder.blocks.2.blocks.12.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380287069376 -> 140380009868256
	140380009868256 [label=AccumulateGrad]
	140380009867872 -> 140380009867968
	140380287875168 [label="encoder.blocks.2.blocks.12.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380287875168 -> 140380009867872
	140380009867872 [label=AccumulateGrad]
	140380009868112 -> 140380009867968
	140380285647984 [label="encoder.blocks.2.blocks.12.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380285647984 -> 140380009868112
	140380009868112 [label=AccumulateGrad]
	140380009867776 -> 140380009867632
	140380142848496 [label="encoder.blocks.2.blocks.12.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380142848496 -> 140380009867776
	140380009867776 [label=AccumulateGrad]
	140380009867584 -> 140380009867488
	140380142846016 [label="encoder.blocks.2.blocks.12.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380142846016 -> 140380009867584
	140380009867584 [label=AccumulateGrad]
	140380009867536 -> 140380009867488
	140380142848976 [label="encoder.blocks.2.blocks.12.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380142848976 -> 140380009867536
	140380009867536 [label=AccumulateGrad]
	140380009867440 -> 140380009866048
	140380009867392 -> 140380009867104
	140380142847776 [label="encoder.blocks.2.blocks.13.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380142847776 -> 140380009867392
	140380009867392 [label=AccumulateGrad]
	140380009866960 -> 140380009867056
	140380142847456 [label="encoder.blocks.2.blocks.13.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380142847456 -> 140380009866960
	140380009866960 [label=AccumulateGrad]
	140380009867200 -> 140380009867056
	140380142847536 [label="encoder.blocks.2.blocks.13.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380142847536 -> 140380009867200
	140380009867200 [label=AccumulateGrad]
	140380009866864 -> 140380009866624
	140380142846576 [label="encoder.blocks.2.blocks.13.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380142846576 -> 140380009866864
	140380009866864 [label=AccumulateGrad]
	140380009866480 -> 140380009866576
	140380142846496 [label="encoder.blocks.2.blocks.13.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380142846496 -> 140380009866480
	140380009866480 [label=AccumulateGrad]
	140380009866720 -> 140380009866576
	140380142846176 [label="encoder.blocks.2.blocks.13.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380142846176 -> 140380009866720
	140380009866720 [label=AccumulateGrad]
	140380009866384 -> 140380009866240
	140380142849776 [label="encoder.blocks.2.blocks.13.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380142849776 -> 140380009866384
	140380009866384 [label=AccumulateGrad]
	140380009866192 -> 140380009866096
	140380142849696 [label="encoder.blocks.2.blocks.13.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380142849696 -> 140380009866192
	140380009866192 [label=AccumulateGrad]
	140380009866144 -> 140380009866096
	140380142848656 [label="encoder.blocks.2.blocks.13.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380142848656 -> 140380009866144
	140380009866144 [label=AccumulateGrad]
	140380009866048 -> 140380009872784
	140380009866000 -> 140380009865712
	140380142846976 [label="encoder.blocks.2.blocks.14.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380142846976 -> 140380009866000
	140380009866000 [label=AccumulateGrad]
	140380009865568 -> 140380009865664
	140380142846736 [label="encoder.blocks.2.blocks.14.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380142846736 -> 140380009865568
	140380009865568 [label=AccumulateGrad]
	140380009865808 -> 140380009865664
	140380142847616 [label="encoder.blocks.2.blocks.14.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380142847616 -> 140380009865808
	140380009865808 [label=AccumulateGrad]
	140380009865472 -> 140380009873216
	140380144891120 [label="encoder.blocks.2.blocks.14.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380144891120 -> 140380009865472
	140380009865472 [label=AccumulateGrad]
	140380009865280 -> 140380009873312
	140380144890960 [label="encoder.blocks.2.blocks.14.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380144890960 -> 140380009865280
	140380009865280 [label=AccumulateGrad]
	140380009865328 -> 140380009873312
	140380144890880 [label="encoder.blocks.2.blocks.14.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380144890880 -> 140380009865328
	140380009865328 [label=AccumulateGrad]
	140380009873120 -> 140380009872976
	140380144893840 [label="encoder.blocks.2.blocks.14.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380144893840 -> 140380009873120
	140380009873120 [label=AccumulateGrad]
	140380009872928 -> 140380009872832
	140380144893760 [label="encoder.blocks.2.blocks.14.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380144893760 -> 140380009872928
	140380009872928 [label=AccumulateGrad]
	140380009872880 -> 140380009872832
	140380144893440 [label="encoder.blocks.2.blocks.14.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380144893440 -> 140380009872880
	140380009872880 [label=AccumulateGrad]
	140380009872784 -> 140380009871392
	140380009872736 -> 140380009872448
	140380144891040 [label="encoder.blocks.2.blocks.15.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380144891040 -> 140380009872736
	140380009872736 [label=AccumulateGrad]
	140380009872304 -> 140380009872400
	140380144891440 [label="encoder.blocks.2.blocks.15.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380144891440 -> 140380009872304
	140380009872304 [label=AccumulateGrad]
	140380009872544 -> 140380009872400
	140380144892240 [label="encoder.blocks.2.blocks.15.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380144892240 -> 140380009872544
	140380009872544 [label=AccumulateGrad]
	140380009872208 -> 140380009871968
	140380144892160 [label="encoder.blocks.2.blocks.15.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380144892160 -> 140380009872208
	140380009872208 [label=AccumulateGrad]
	140380009871824 -> 140380009871920
	140380144892880 [label="encoder.blocks.2.blocks.15.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380144892880 -> 140380009871824
	140380009871824 [label=AccumulateGrad]
	140380009872064 -> 140380009871920
	140380144892000 [label="encoder.blocks.2.blocks.15.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380144892000 -> 140380009872064
	140380009872064 [label=AccumulateGrad]
	140380009871728 -> 140380009871584
	140380144893600 [label="encoder.blocks.2.blocks.15.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380144893600 -> 140380009871728
	140380009871728 [label=AccumulateGrad]
	140380009871536 -> 140380009871440
	140380144893360 [label="encoder.blocks.2.blocks.15.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380144893360 -> 140380009871536
	140380009871536 [label=AccumulateGrad]
	140380009871488 -> 140380009871440
	140380144892480 [label="encoder.blocks.2.blocks.15.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380144892480 -> 140380009871488
	140380009871488 [label=AccumulateGrad]
	140380009871392 -> 140380009870000
	140380009871344 -> 140380009871056
	140380143189024 [label="encoder.blocks.2.blocks.16.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380143189024 -> 140380009871344
	140380009871344 [label=AccumulateGrad]
	140380009870912 -> 140380009871008
	140380143186784 [label="encoder.blocks.2.blocks.16.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380143186784 -> 140380009870912
	140380009870912 [label=AccumulateGrad]
	140380009871152 -> 140380009871008
	140380143187424 [label="encoder.blocks.2.blocks.16.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380143187424 -> 140380009871152
	140380009871152 [label=AccumulateGrad]
	140380009870816 -> 140380009870576
	140380143186384 [label="encoder.blocks.2.blocks.16.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380143186384 -> 140380009870816
	140380009870816 [label=AccumulateGrad]
	140380009870432 -> 140380009870528
	140380143186304 [label="encoder.blocks.2.blocks.16.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380143186304 -> 140380009870432
	140380009870432 [label=AccumulateGrad]
	140380009870672 -> 140380009870528
	140380143186064 [label="encoder.blocks.2.blocks.16.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380143186064 -> 140380009870672
	140380009870672 [label=AccumulateGrad]
	140380009870336 -> 140380009870192
	140380143187824 [label="encoder.blocks.2.blocks.16.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380143187824 -> 140380009870336
	140380009870336 [label=AccumulateGrad]
	140380009870144 -> 140380009870048
	140380143188304 [label="encoder.blocks.2.blocks.16.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380143188304 -> 140380009870144
	140380009870144 [label=AccumulateGrad]
	140380009870096 -> 140380009870048
	140380143188224 [label="encoder.blocks.2.blocks.16.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380143188224 -> 140380009870096
	140380009870096 [label=AccumulateGrad]
	140380009870000 -> 140380009848064
	140380009869952 -> 140380009869664
	140380143188624 [label="encoder.blocks.2.blocks.17.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380143188624 -> 140380009869952
	140380009869952 [label=AccumulateGrad]
	140380009869520 -> 140380009869616
	140380143187744 [label="encoder.blocks.2.blocks.17.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380143187744 -> 140380009869520
	140380009869520 [label=AccumulateGrad]
	140380009869760 -> 140380009869616
	140380143187664 [label="encoder.blocks.2.blocks.17.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380143187664 -> 140380009869760
	140380009869760 [label=AccumulateGrad]
	140380009869424 -> 140380009848640
	140380143187024 [label="encoder.blocks.2.blocks.17.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380143187024 -> 140380009869424
	140380009869424 [label=AccumulateGrad]
	140380009848496 -> 140380009848592
	140380143186944 [label="encoder.blocks.2.blocks.17.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380143186944 -> 140380009848496
	140380009848496 [label=AccumulateGrad]
	140380009848736 -> 140380009848592
	140380143186544 [label="encoder.blocks.2.blocks.17.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380143186544 -> 140380009848736
	140380009848736 [label=AccumulateGrad]
	140380009848400 -> 140380009848256
	140380143186144 [label="encoder.blocks.2.blocks.17.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380143186144 -> 140380009848400
	140380009848400 [label=AccumulateGrad]
	140380009848208 -> 140380009848112
	140380143187904 [label="encoder.blocks.2.blocks.17.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380143187904 -> 140380009848208
	140380009848208 [label=AccumulateGrad]
	140380009848160 -> 140380009848112
	140380143189264 [label="encoder.blocks.2.blocks.17.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380143189264 -> 140380009848160
	140380009848160 [label=AccumulateGrad]
	140380009848064 -> 140380009846672
	140380009848016 -> 140380009847728
	140380143186704 [label="encoder.blocks.2.blocks.18.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380143186704 -> 140380009848016
	140380009848016 [label=AccumulateGrad]
	140380009847584 -> 140380009847680
	140380143188784 [label="encoder.blocks.2.blocks.18.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380143188784 -> 140380009847584
	140380009847584 [label=AccumulateGrad]
	140380009847824 -> 140380009847680
	140380143188384 [label="encoder.blocks.2.blocks.18.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380143188384 -> 140380009847824
	140380009847824 [label=AccumulateGrad]
	140380009847488 -> 140380009847248
	140380147296352 [label="encoder.blocks.2.blocks.18.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380147296352 -> 140380009847488
	140380009847488 [label=AccumulateGrad]
	140380009847104 -> 140380009847200
	140380147296432 [label="encoder.blocks.2.blocks.18.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380147296432 -> 140380009847104
	140380009847104 [label=AccumulateGrad]
	140380009847344 -> 140380009847200
	140380147296592 [label="encoder.blocks.2.blocks.18.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380147296592 -> 140380009847344
	140380009847344 [label=AccumulateGrad]
	140380009847008 -> 140380009846864
	140380147295472 [label="encoder.blocks.2.blocks.18.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380147295472 -> 140380009847008
	140380009847008 [label=AccumulateGrad]
	140380009846816 -> 140380009846720
	140380147295632 [label="encoder.blocks.2.blocks.18.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380147295632 -> 140380009846816
	140380009846816 [label=AccumulateGrad]
	140380009846768 -> 140380009846720
	140380147295872 [label="encoder.blocks.2.blocks.18.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380147295872 -> 140380009846768
	140380009846768 [label=AccumulateGrad]
	140380009846672 -> 140380009845280
	140380009846624 -> 140380009846336
	140380147296112 [label="encoder.blocks.2.blocks.19.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380147296112 -> 140380009846624
	140380009846624 [label=AccumulateGrad]
	140380009846192 -> 140380009846288
	140380147295152 [label="encoder.blocks.2.blocks.19.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380147295152 -> 140380009846192
	140380009846192 [label=AccumulateGrad]
	140380009846432 -> 140380009846288
	140380147295952 [label="encoder.blocks.2.blocks.19.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380147295952 -> 140380009846432
	140380009846432 [label=AccumulateGrad]
	140380009846096 -> 140380009845856
	140380147294832 [label="encoder.blocks.2.blocks.19.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380147294832 -> 140380009846096
	140380009846096 [label=AccumulateGrad]
	140380009845712 -> 140380009845808
	140380147294272 [label="encoder.blocks.2.blocks.19.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380147294272 -> 140380009845712
	140380009845712 [label=AccumulateGrad]
	140380009845952 -> 140380009845808
	140380147294432 [label="encoder.blocks.2.blocks.19.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380147294432 -> 140380009845952
	140380009845952 [label=AccumulateGrad]
	140380009845616 -> 140380009845472
	140380147296192 [label="encoder.blocks.2.blocks.19.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380147296192 -> 140380009845616
	140380009845616 [label=AccumulateGrad]
	140380009845424 -> 140380009845328
	140380147297152 [label="encoder.blocks.2.blocks.19.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380147297152 -> 140380009845424
	140380009845424 [label=AccumulateGrad]
	140380009845376 -> 140380009845328
	140380147294912 [label="encoder.blocks.2.blocks.19.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380147294912 -> 140380009845376
	140380009845376 [label=AccumulateGrad]
	140380009845280 -> 140380009856112
	140380009845232 -> 140380009844944
	140380147297072 [label="encoder.blocks.2.blocks.20.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380147297072 -> 140380009845232
	140380009845232 [label=AccumulateGrad]
	140380009844800 -> 140380009844896
	140380147297232 [label="encoder.blocks.2.blocks.20.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380147297232 -> 140380009844800
	140380009844800 [label=AccumulateGrad]
	140380009845040 -> 140380009844896
	140380147296512 [label="encoder.blocks.2.blocks.20.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380147296512 -> 140380009845040
	140380009845040 [label=AccumulateGrad]
	140380009856928 -> 140380009856688
	140380143078272 [label="encoder.blocks.2.blocks.20.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380143078272 -> 140380009856928
	140380009856928 [label=AccumulateGrad]
	140380009856544 -> 140380009856640
	140380141878624 [label="encoder.blocks.2.blocks.20.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380141878624 -> 140380009856544
	140380009856544 [label=AccumulateGrad]
	140380009856784 -> 140380009856640
	140380141878544 [label="encoder.blocks.2.blocks.20.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380141878544 -> 140380009856784
	140380009856784 [label=AccumulateGrad]
	140380009856448 -> 140380009856304
	140380141879184 [label="encoder.blocks.2.blocks.20.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380141879184 -> 140380009856448
	140380009856448 [label=AccumulateGrad]
	140380009856256 -> 140380009856160
	140380141878384 [label="encoder.blocks.2.blocks.20.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380141878384 -> 140380009856256
	140380009856256 [label=AccumulateGrad]
	140380009856208 -> 140380009856160
	140380141878304 [label="encoder.blocks.2.blocks.20.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380141878304 -> 140380009856208
	140380009856208 [label=AccumulateGrad]
	140380009856112 -> 140380009854720
	140380009856064 -> 140380009855776
	140380141877264 [label="encoder.blocks.2.blocks.21.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380141877264 -> 140380009856064
	140380009856064 [label=AccumulateGrad]
	140380009855632 -> 140380009855728
	140380141877184 [label="encoder.blocks.2.blocks.21.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380141877184 -> 140380009855632
	140380009855632 [label=AccumulateGrad]
	140380009855872 -> 140380009855728
	140380141877024 [label="encoder.blocks.2.blocks.21.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380141877024 -> 140380009855872
	140380009855872 [label=AccumulateGrad]
	140380009855536 -> 140380009855296
	140380141877664 [label="encoder.blocks.2.blocks.21.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380141877664 -> 140380009855536
	140380009855536 [label=AccumulateGrad]
	140380009855152 -> 140380009855248
	140380141877824 [label="encoder.blocks.2.blocks.21.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380141877824 -> 140380009855152
	140380009855152 [label=AccumulateGrad]
	140380009855392 -> 140380009855248
	140380141876064 [label="encoder.blocks.2.blocks.21.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380141876064 -> 140380009855392
	140380009855392 [label=AccumulateGrad]
	140380009855056 -> 140380009854912
	140380141876944 [label="encoder.blocks.2.blocks.21.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380141876944 -> 140380009855056
	140380009855056 [label=AccumulateGrad]
	140380009854864 -> 140380009854768
	140380141877424 [label="encoder.blocks.2.blocks.21.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380141877424 -> 140380009854864
	140380009854864 [label=AccumulateGrad]
	140380009854816 -> 140380009854768
	140380141877344 [label="encoder.blocks.2.blocks.21.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380141877344 -> 140380009854816
	140380009854816 [label=AccumulateGrad]
	140380009854720 -> 140380009853328
	140380009854672 -> 140380009854384
	140380141876384 [label="encoder.blocks.2.blocks.22.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380141876384 -> 140380009854672
	140380009854672 [label=AccumulateGrad]
	140380009854240 -> 140380009854336
	140380141876304 [label="encoder.blocks.2.blocks.22.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380141876304 -> 140380009854240
	140380009854240 [label=AccumulateGrad]
	140380009854480 -> 140380009854336
	140380141876144 [label="encoder.blocks.2.blocks.22.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380141876144 -> 140380009854480
	140380009854480 [label=AccumulateGrad]
	140380009854144 -> 140380009853904
	140380141876784 [label="encoder.blocks.2.blocks.22.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380141876784 -> 140380009854144
	140380009854144 [label=AccumulateGrad]
	140380009853760 -> 140380009853856
	140380141875424 [label="encoder.blocks.2.blocks.22.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380141875424 -> 140380009853760
	140380009853760 [label=AccumulateGrad]
	140380009854000 -> 140380009853856
	140380141875664 [label="encoder.blocks.2.blocks.22.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380141875664 -> 140380009854000
	140380009854000 [label=AccumulateGrad]
	140380009853664 -> 140380009853520
	140380135800080 [label="encoder.blocks.2.blocks.22.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380135800080 -> 140380009853664
	140380009853664 [label=AccumulateGrad]
	140380009853472 -> 140380009853376
	140380135797600 [label="encoder.blocks.2.blocks.22.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380135797600 -> 140380009853472
	140380009853472 [label=AccumulateGrad]
	140380009853424 -> 140380009853376
	140380135800720 [label="encoder.blocks.2.blocks.22.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380135800720 -> 140380009853424
	140380009853424 [label=AccumulateGrad]
	140380009853328 -> 140380009831392
	140380009853280 -> 140380009853040
	140380135799120 [label="encoder.blocks.2.blocks.23.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380135799120 -> 140380009853280
	140380009853280 [label=AccumulateGrad]
	140380009852992 -> 140380009832400
	140380135800000 [label="encoder.blocks.2.blocks.23.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380135800000 -> 140380009852992
	140380009852992 [label=AccumulateGrad]
	140380009853088 -> 140380009832400
	140380135798880 [label="encoder.blocks.2.blocks.23.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380135798880 -> 140380009853088
	140380009853088 [label=AccumulateGrad]
	140380009832208 -> 140380009831968
	140380135800480 [label="encoder.blocks.2.blocks.23.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380135800480 -> 140380009832208
	140380009832208 [label=AccumulateGrad]
	140380009831824 -> 140380009831920
	140380135800160 [label="encoder.blocks.2.blocks.23.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380135800160 -> 140380009831824
	140380009831824 [label=AccumulateGrad]
	140380009832064 -> 140380009831920
	140380135797920 [label="encoder.blocks.2.blocks.23.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380135797920 -> 140380009832064
	140380009832064 [label=AccumulateGrad]
	140380009831728 -> 140380009831584
	140380135799840 [label="encoder.blocks.2.blocks.23.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380135799840 -> 140380009831728
	140380009831728 [label=AccumulateGrad]
	140380009831536 -> 140380009831440
	140380135800400 [label="encoder.blocks.2.blocks.23.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380135800400 -> 140380009831536
	140380009831536 [label=AccumulateGrad]
	140380009831488 -> 140380009831440
	140380135799360 [label="encoder.blocks.2.blocks.23.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380135799360 -> 140380009831488
	140380009831488 [label=AccumulateGrad]
	140380009831392 -> 140380009830000
	140380009831344 -> 140380009831056
	140380135800640 [label="encoder.blocks.2.blocks.24.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380135800640 -> 140380009831344
	140380009831344 [label=AccumulateGrad]
	140380009830912 -> 140380009831008
	140380135800240 [label="encoder.blocks.2.blocks.24.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380135800240 -> 140380009830912
	140380009830912 [label=AccumulateGrad]
	140380009831152 -> 140380009831008
	140380135798800 [label="encoder.blocks.2.blocks.24.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380135798800 -> 140380009831152
	140380009831152 [label=AccumulateGrad]
	140380009830816 -> 140380009830576
	140380135797360 [label="encoder.blocks.2.blocks.24.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380135797360 -> 140380009830816
	140380009830816 [label=AccumulateGrad]
	140380009830432 -> 140380009830528
	140380135797520 [label="encoder.blocks.2.blocks.24.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380135797520 -> 140380009830432
	140380009830432 [label=AccumulateGrad]
	140380009830672 -> 140380009830528
	140380135797840 [label="encoder.blocks.2.blocks.24.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380135797840 -> 140380009830672
	140380009830672 [label=AccumulateGrad]
	140380009830336 -> 140380009830192
	140380135798240 [label="encoder.blocks.2.blocks.24.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380135798240 -> 140380009830336
	140380009830336 [label=AccumulateGrad]
	140380009830144 -> 140380009830048
	140380135796880 [label="encoder.blocks.2.blocks.24.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380135796880 -> 140380009830144
	140380009830144 [label=AccumulateGrad]
	140380009830096 -> 140380009830048
	140380135800320 [label="encoder.blocks.2.blocks.24.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380135800320 -> 140380009830096
	140380009830096 [label=AccumulateGrad]
	140380009830000 -> 140380009828608
	140380009829952 -> 140380009829664
	140380142915072 [label="encoder.blocks.2.blocks.25.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380142915072 -> 140380009829952
	140380009829952 [label=AccumulateGrad]
	140380009829520 -> 140380009829616
	140380142913792 [label="encoder.blocks.2.blocks.25.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380142913792 -> 140380009829520
	140380009829520 [label=AccumulateGrad]
	140380009829760 -> 140380009829616
	140380142913952 [label="encoder.blocks.2.blocks.25.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380142913952 -> 140380009829760
	140380009829760 [label=AccumulateGrad]
	140380009829424 -> 140380009829184
	140380142915312 [label="encoder.blocks.2.blocks.25.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380142915312 -> 140380009829424
	140380009829424 [label=AccumulateGrad]
	140380009829040 -> 140380009829136
	140380142914912 [label="encoder.blocks.2.blocks.25.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380142914912 -> 140380009829040
	140380009829040 [label=AccumulateGrad]
	140380009829280 -> 140380009829136
	140380142914832 [label="encoder.blocks.2.blocks.25.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380142914832 -> 140380009829280
	140380009829280 [label=AccumulateGrad]
	140380009828944 -> 140380009828800
	140380142915232 [label="encoder.blocks.2.blocks.25.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380142915232 -> 140380009828944
	140380009828944 [label=AccumulateGrad]
	140380009828752 -> 140380009828656
	140380148100608 [label="encoder.blocks.2.blocks.25.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380148100608 -> 140380009828752
	140380009828752 [label=AccumulateGrad]
	140380009828704 -> 140380009828656
	140380148100768 [label="encoder.blocks.2.blocks.25.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380148100768 -> 140380009828704
	140380009828704 [label=AccumulateGrad]
	140380009828608 -> 140380009835344
	140380009828560 -> 140380009836400
	140380007994208 [label="encoder.blocks.2.blocks.26.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380007994208 -> 140380009828560
	140380009828560 [label=AccumulateGrad]
	140380009836256 -> 140380009836352
	140380007994128 [label="encoder.blocks.2.blocks.26.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380007994128 -> 140380009836256
	140380009836256 [label=AccumulateGrad]
	140380009836496 -> 140380009836352
	140380007994048 [label="encoder.blocks.2.blocks.26.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380007994048 -> 140380009836496
	140380009836496 [label=AccumulateGrad]
	140380009836160 -> 140380009835920
	140380007995248 [label="encoder.blocks.2.blocks.26.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380007995248 -> 140380009836160
	140380009836160 [label=AccumulateGrad]
	140380009835776 -> 140380009835872
	140380007995168 [label="encoder.blocks.2.blocks.26.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380007995168 -> 140380009835776
	140380009835776 [label=AccumulateGrad]
	140380009836016 -> 140380009835872
	140380007995088 [label="encoder.blocks.2.blocks.26.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380007995088 -> 140380009836016
	140380009836016 [label=AccumulateGrad]
	140380009835680 -> 140380009835536
	140380007994688 [label="encoder.blocks.2.blocks.26.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380007994688 -> 140380009835680
	140380009835680 [label=AccumulateGrad]
	140380009835488 -> 140380009835392
	140380007995808 [label="encoder.blocks.2.blocks.26.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380007995808 -> 140380009835488
	140380009835488 [label=AccumulateGrad]
	140380009835440 -> 140380009835392
	140380007996368 [label="encoder.blocks.2.blocks.26.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380007996368 -> 140380009835440
	140380009835440 [label=AccumulateGrad]
	140380009835344 -> 140380009833952
	140380009835296 -> 140380009835008
	140380007996608 [label="encoder.blocks.2.blocks.27.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380007996608 -> 140380009835296
	140380009835296 [label=AccumulateGrad]
	140380009834864 -> 140380009834960
	140380007995488 [label="encoder.blocks.2.blocks.27.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380007995488 -> 140380009834864
	140380009834864 [label=AccumulateGrad]
	140380009835104 -> 140380009834960
	140380007995408 [label="encoder.blocks.2.blocks.27.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380007995408 -> 140380009835104
	140380009835104 [label=AccumulateGrad]
	140380009834768 -> 140380009834528
	140380003098688 [label="encoder.blocks.2.blocks.27.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380003098688 -> 140380009834768
	140380009834768 [label=AccumulateGrad]
	140380009834384 -> 140380009834480
	140380003102448 [label="encoder.blocks.2.blocks.27.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380003102448 -> 140380009834384
	140380009834384 [label=AccumulateGrad]
	140380009834624 -> 140380009834480
	140380003102128 [label="encoder.blocks.2.blocks.27.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380003102128 -> 140380009834624
	140380009834624 [label=AccumulateGrad]
	140380009834288 -> 140380009834144
	140380003099408 [label="encoder.blocks.2.blocks.27.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380003099408 -> 140380009834288
	140380009834288 [label=AccumulateGrad]
	140380009834096 -> 140380009834000
	140380003101328 [label="encoder.blocks.2.blocks.27.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380003101328 -> 140380009834096
	140380009834096 [label=AccumulateGrad]
	140380009834048 -> 140380009834000
	140380003100128 [label="encoder.blocks.2.blocks.27.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380003100128 -> 140380009834048
	140380009834048 [label=AccumulateGrad]
	140380009833952 -> 140380009832560
	140380009833904 -> 140380009833616
	140380003100848 [label="encoder.blocks.2.blocks.28.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380003100848 -> 140380009833904
	140380009833904 [label=AccumulateGrad]
	140380009833472 -> 140380009833568
	140380003101408 [label="encoder.blocks.2.blocks.28.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380003101408 -> 140380009833472
	140380009833472 [label=AccumulateGrad]
	140380009833712 -> 140380009833568
	140380003101968 [label="encoder.blocks.2.blocks.28.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380003101968 -> 140380009833712
	140380009833712 [label=AccumulateGrad]
	140380009833376 -> 140380009833136
	140380003099488 [label="encoder.blocks.2.blocks.28.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380003099488 -> 140380009833376
	140380009833376 [label=AccumulateGrad]
	140380009832992 -> 140380009833088
	140380003098768 [label="encoder.blocks.2.blocks.28.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380003098768 -> 140380009832992
	140380009832992 [label=AccumulateGrad]
	140380009833232 -> 140380009833088
	140380003101488 [label="encoder.blocks.2.blocks.28.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380003101488 -> 140380009833232
	140380009833232 [label=AccumulateGrad]
	140380009832896 -> 140380009832752
	140380003099888 [label="encoder.blocks.2.blocks.28.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380003099888 -> 140380009832896
	140380009832896 [label=AccumulateGrad]
	140380009832704 -> 140380009832608
	140380003099968 [label="encoder.blocks.2.blocks.28.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380003099968 -> 140380009832704
	140380009832704 [label=AccumulateGrad]
	140380009832656 -> 140380009832608
	140380003100048 [label="encoder.blocks.2.blocks.28.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380003100048 -> 140380009832656
	140380009832656 [label=AccumulateGrad]
	140380009832560 -> 140380009822912
	140380009824208 -> 140380009823968
	140380003099648 [label="encoder.blocks.2.blocks.29.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380003099648 -> 140380009824208
	140380009824208 [label=AccumulateGrad]
	140380009823824 -> 140380009823920
	140380003101088 [label="encoder.blocks.2.blocks.29.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380003101088 -> 140380009823824
	140380009823824 [label=AccumulateGrad]
	140380009824064 -> 140380009823920
	140380003101248 [label="encoder.blocks.2.blocks.29.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380003101248 -> 140380009824064
	140380009824064 [label=AccumulateGrad]
	140380009823728 -> 140380009823488
	140380003102368 [label="encoder.blocks.2.blocks.29.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380003102368 -> 140380009823728
	140380009823728 [label=AccumulateGrad]
	140380009823344 -> 140380009823440
	140380003101888 [label="encoder.blocks.2.blocks.29.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380003101888 -> 140380009823344
	140380009823344 [label=AccumulateGrad]
	140380009823584 -> 140380009823440
	140380003102608 [label="encoder.blocks.2.blocks.29.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380003102608 -> 140380009823584
	140380009823584 [label=AccumulateGrad]
	140380009823248 -> 140380009823104
	140380004541280 [label="encoder.blocks.2.blocks.29.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380004541280 -> 140380009823248
	140380009823248 [label=AccumulateGrad]
	140380009823056 -> 140380009822960
	140380004543120 [label="encoder.blocks.2.blocks.29.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380004543120 -> 140380009823056
	140380009823056 [label=AccumulateGrad]
	140380009823008 -> 140380009822960
	140380004543680 [label="encoder.blocks.2.blocks.29.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380004543680 -> 140380009823008
	140380009823008 [label=AccumulateGrad]
	140380009822912 -> 140380009821520
	140380009822864 -> 140380009822576
	140380004542960 [label="encoder.blocks.2.blocks.30.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380004542960 -> 140380009822864
	140380009822864 [label=AccumulateGrad]
	140380009822432 -> 140380009822528
	140380004541120 [label="encoder.blocks.2.blocks.30.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380004541120 -> 140380009822432
	140380009822432 [label=AccumulateGrad]
	140380009822672 -> 140380009822528
	140380004540480 [label="encoder.blocks.2.blocks.30.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380004540480 -> 140380009822672
	140380009822672 [label=AccumulateGrad]
	140380009822336 -> 140380009822096
	140380004544000 [label="encoder.blocks.2.blocks.30.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380004544000 -> 140380009822336
	140380009822336 [label=AccumulateGrad]
	140380009821952 -> 140380009822048
	140380004541440 [label="encoder.blocks.2.blocks.30.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380004541440 -> 140380009821952
	140380009821952 [label=AccumulateGrad]
	140380009822192 -> 140380009822048
	140380004543280 [label="encoder.blocks.2.blocks.30.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380004543280 -> 140380009822192
	140380009822192 [label=AccumulateGrad]
	140380009821856 -> 140380009821712
	140380004544080 [label="encoder.blocks.2.blocks.30.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380004544080 -> 140380009821856
	140380009821856 [label=AccumulateGrad]
	140380009821664 -> 140380009821568
	140380004543760 [label="encoder.blocks.2.blocks.30.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380004543760 -> 140380009821664
	140380009821664 [label=AccumulateGrad]
	140380009821616 -> 140380009821568
	140380004543040 [label="encoder.blocks.2.blocks.30.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380004543040 -> 140380009821616
	140380009821616 [label=AccumulateGrad]
	140380009821520 -> 140380009787296
	140380009821472 -> 140380009821184
	140380004543520 [label="encoder.blocks.2.blocks.31.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380004543520 -> 140380009821472
	140380009821472 [label=AccumulateGrad]
	140380009821040 -> 140380009821136
	140380004543360 [label="encoder.blocks.2.blocks.31.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380004543360 -> 140380009821040
	140380009821040 [label=AccumulateGrad]
	140380009821280 -> 140380009821136
	140380004542000 [label="encoder.blocks.2.blocks.31.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380004542000 -> 140380009821280
	140380009821280 [label=AccumulateGrad]
	140380009820944 -> 140380009820704
	140380004542560 [label="encoder.blocks.2.blocks.31.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380004542560 -> 140380009820944
	140380009820944 [label=AccumulateGrad]
	140380009820560 -> 140380009820656
	140380004540640 [label="encoder.blocks.2.blocks.31.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380004540640 -> 140380009820560
	140380009820560 [label=AccumulateGrad]
	140380009820800 -> 140380009820656
	140380004540560 [label="encoder.blocks.2.blocks.31.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380004540560 -> 140380009820800
	140380009820800 [label=AccumulateGrad]
	140380009820464 -> 140380009820320
	140380004541520 [label="encoder.blocks.2.blocks.31.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380004541520 -> 140380009820464
	140380009820464 [label=AccumulateGrad]
	140380009820272 -> 140380009787344
	140380004544320 [label="encoder.blocks.2.blocks.31.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380004544320 -> 140380009820272
	140380009820272 [label=AccumulateGrad]
	140380009820224 -> 140380009787344
	140380004542240 [label="encoder.blocks.2.blocks.31.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380004542240 -> 140380009820224
	140380009820224 [label=AccumulateGrad]
	140380009787296 -> 140380009785904
	140380009787248 -> 140380009786960
	140380003442016 [label="encoder.blocks.2.blocks.32.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380003442016 -> 140380009787248
	140380009787248 [label=AccumulateGrad]
	140380009786816 -> 140380009786912
	140380003441936 [label="encoder.blocks.2.blocks.32.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380003441936 -> 140380009786816
	140380009786816 [label=AccumulateGrad]
	140380009787056 -> 140380009786912
	140380003441616 [label="encoder.blocks.2.blocks.32.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380003441616 -> 140380009787056
	140380009787056 [label=AccumulateGrad]
	140380009786720 -> 140380009786480
	140380003441376 [label="encoder.blocks.2.blocks.32.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380003441376 -> 140380009786720
	140380009786720 [label=AccumulateGrad]
	140380009786336 -> 140380009786432
	140380003441056 [label="encoder.blocks.2.blocks.32.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380003441056 -> 140380009786336
	140380009786336 [label=AccumulateGrad]
	140380009786576 -> 140380009786432
	140380003440336 [label="encoder.blocks.2.blocks.32.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380003440336 -> 140380009786576
	140380009786576 [label=AccumulateGrad]
	140380009786240 -> 140380009786096
	140380003440496 [label="encoder.blocks.2.blocks.32.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380003440496 -> 140380009786240
	140380009786240 [label=AccumulateGrad]
	140380009786048 -> 140380009785952
	140380003439776 [label="encoder.blocks.2.blocks.32.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380003439776 -> 140380009786048
	140380009786048 [label=AccumulateGrad]
	140380009786000 -> 140380009785952
	140380003440736 [label="encoder.blocks.2.blocks.32.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380003440736 -> 140380009786000
	140380009786000 [label=AccumulateGrad]
	140380009785904 -> 140380009784560
	140380009785856 -> 140380009785568
	140380003439216 [label="encoder.blocks.2.blocks.33.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380003439216 -> 140380009785856
	140380009785856 [label=AccumulateGrad]
	140380009785424 -> 140380009785520
	140380003440176 [label="encoder.blocks.2.blocks.33.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380003440176 -> 140380009785424
	140380009785424 [label=AccumulateGrad]
	140380009785664 -> 140380009785520
	140380003440096 [label="encoder.blocks.2.blocks.33.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380003440096 -> 140380009785664
	140380009785664 [label=AccumulateGrad]
	140380009785328 -> 140380009785184
	140380003439616 [label="encoder.blocks.2.blocks.33.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380003439616 -> 140380009785328
	140380009785328 [label=AccumulateGrad]
	140380009785136 -> 140380009785088
	140380003439536 [label="encoder.blocks.2.blocks.33.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380003439536 -> 140380009785136
	140380009785136 [label=AccumulateGrad]
	140380009784992 -> 140380009785088
	140380003439456 [label="encoder.blocks.2.blocks.33.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380003439456 -> 140380009784992
	140380009784992 [label=AccumulateGrad]
	140380009784896 -> 140380009784752
	140380003438896 [label="encoder.blocks.2.blocks.33.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380003438896 -> 140380009784896
	140380009784896 [label=AccumulateGrad]
	140380009784704 -> 140380009784608
	140380003442576 [label="encoder.blocks.2.blocks.33.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380003442576 -> 140380009784704
	140380009784704 [label=AccumulateGrad]
	140380009784656 -> 140380009784608
	140380003442176 [label="encoder.blocks.2.blocks.33.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380003442176 -> 140380009784656
	140380009784656 [label=AccumulateGrad]
	140380009784560 -> 140380009799584
	140380009784512 -> 140380009784320
	140380003441456 [label="encoder.blocks.2.blocks.34.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380003441456 -> 140380009784512
	140380009784512 [label=AccumulateGrad]
	140380009784272 -> 140380009784224
	140380003442096 [label="encoder.blocks.2.blocks.34.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380003442096 -> 140380009784272
	140380009784272 [label=AccumulateGrad]
	140380009784128 -> 140380009784224
	140380010745920 [label="encoder.blocks.2.blocks.34.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380010745920 -> 140380009784128
	140380009784128 [label=AccumulateGrad]
	140380009784032 -> 140380009783888
	140380010746320 [label="encoder.blocks.2.blocks.34.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380010746320 -> 140380009784032
	140380009784032 [label=AccumulateGrad]
	140380009783840 -> 140380009783792
	140380010746400 [label="encoder.blocks.2.blocks.34.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380010746400 -> 140380009783840
	140380009783840 [label=AccumulateGrad]
	140380009783696 -> 140380009783792
	140380010746480 [label="encoder.blocks.2.blocks.34.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380010746480 -> 140380009783696
	140380009783696 [label=AccumulateGrad]
	140380009783600 -> 140380009783456
	140380010746880 [label="encoder.blocks.2.blocks.34.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380010746880 -> 140380009783600
	140380009783600 [label=AccumulateGrad]
	140380009783408 -> 140380009799632
	140380010746960 [label="encoder.blocks.2.blocks.34.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380010746960 -> 140380009783408
	140380009783408 [label=AccumulateGrad]
	140380009783360 -> 140380009799632
	140380010747040 [label="encoder.blocks.2.blocks.34.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380010747040 -> 140380009783360
	140380009783360 [label=AccumulateGrad]
	140380009799584 -> 140380009798288
	140380009799536 -> 140380009799344
	140380010747440 [label="encoder.blocks.2.blocks.35.blocks.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140380010747440 -> 140380009799536
	140380009799536 [label=AccumulateGrad]
	140380009799296 -> 140380009799248
	140380010747520 [label="encoder.blocks.2.blocks.35.blocks.0.bn.weight
 (256)" fillcolor=lightblue]
	140380010747520 -> 140380009799296
	140380009799296 [label=AccumulateGrad]
	140380009799152 -> 140380009799248
	140380010747600 [label="encoder.blocks.2.blocks.35.blocks.0.bn.bias
 (256)" fillcolor=lightblue]
	140380010747600 -> 140380009799152
	140380009799152 [label=AccumulateGrad]
	140380009799056 -> 140380009798912
	140380010748000 [label="encoder.blocks.2.blocks.35.blocks.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140380010748000 -> 140380009799056
	140380009799056 [label=AccumulateGrad]
	140380009798864 -> 140380009798816
	140380010748080 [label="encoder.blocks.2.blocks.35.blocks.2.bn.weight
 (256)" fillcolor=lightblue]
	140380010748080 -> 140380009798864
	140380009798864 [label=AccumulateGrad]
	140380009798720 -> 140380009798816
	140380010748160 [label="encoder.blocks.2.blocks.35.blocks.2.bn.bias
 (256)" fillcolor=lightblue]
	140380010748160 -> 140380009798720
	140380009798720 [label=AccumulateGrad]
	140380009798624 -> 140380009798480
	140380010748560 [label="encoder.blocks.2.blocks.35.blocks.4.conv.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140380010748560 -> 140380009798624
	140380009798624 [label=AccumulateGrad]
	140380009798432 -> 140380009798336
	140380010748640 [label="encoder.blocks.2.blocks.35.blocks.4.bn.weight
 (1024)" fillcolor=lightblue]
	140380010748640 -> 140380009798432
	140380009798432 [label=AccumulateGrad]
	140380009798384 -> 140380009798336
	140380010748720 [label="encoder.blocks.2.blocks.35.blocks.4.bn.bias
 (1024)" fillcolor=lightblue]
	140380010748720 -> 140380009798384
	140380009798384 [label=AccumulateGrad]
	140380009798288 -> 140380009798192
	140380009798144 -> 140380009798000
	140380010749680 [label="encoder.blocks.3.blocks.0.blocks.0.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	140380010749680 -> 140380009798144
	140380009798144 [label=AccumulateGrad]
	140380009797952 -> 140380009797904
	140380010749760 [label="encoder.blocks.3.blocks.0.blocks.0.bn.weight
 (512)" fillcolor=lightblue]
	140380010749760 -> 140380009797952
	140380009797952 [label=AccumulateGrad]
	140380009797808 -> 140380009797904
	140380010749840 [label="encoder.blocks.3.blocks.0.blocks.0.bn.bias
 (512)" fillcolor=lightblue]
	140380010749840 -> 140380009797808
	140380009797808 [label=AccumulateGrad]
	140380009797712 -> 140380009797568
	140380010897792 [label="encoder.blocks.3.blocks.0.blocks.2.conv.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140380010897792 -> 140380009797712
	140380009797712 [label=AccumulateGrad]
	140380009797520 -> 140380009797472
	140380010897872 [label="encoder.blocks.3.blocks.0.blocks.2.bn.weight
 (512)" fillcolor=lightblue]
	140380010897872 -> 140380009797520
	140380009797520 [label=AccumulateGrad]
	140380009797376 -> 140380009797472
	140380010897952 [label="encoder.blocks.3.blocks.0.blocks.2.bn.bias
 (512)" fillcolor=lightblue]
	140380010897952 -> 140380009797376
	140380009797376 [label=AccumulateGrad]
	140380009797280 -> 140380009797136
	140380010898352 [label="encoder.blocks.3.blocks.0.blocks.4.conv.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140380010898352 -> 140380009797280
	140380009797280 [label=AccumulateGrad]
	140380009797088 -> 140380009796992
	140380010898432 [label="encoder.blocks.3.blocks.0.blocks.4.bn.weight
 (2048)" fillcolor=lightblue]
	140380010898432 -> 140380009797088
	140380009797088 [label=AccumulateGrad]
	140380009797040 -> 140380009796992
	140380010898512 [label="encoder.blocks.3.blocks.0.blocks.4.bn.bias
 (2048)" fillcolor=lightblue]
	140380010898512 -> 140380009797040
	140380009797040 [label=AccumulateGrad]
	140380009796944 -> 140380009795696
	140380009796944 [label=CudnnBatchNormBackward0]
	140380009797664 -> 140380009796944
	140380009797664 [label=CudnnConvolutionBackward0]
	140380009798192 -> 140380009797664
	140380009798048 -> 140380009797664
	140380010749120 [label="encoder.blocks.3.blocks.0.shortcut.conv.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	140380010749120 -> 140380009798048
	140380009798048 [label=AccumulateGrad]
	140380009797232 -> 140380009796944
	140380010749200 [label="encoder.blocks.3.blocks.0.shortcut.bn.weight
 (2048)" fillcolor=lightblue]
	140380010749200 -> 140380009797232
	140380009797232 [label=AccumulateGrad]
	140380009797184 -> 140380009796944
	140380010749280 [label="encoder.blocks.3.blocks.0.shortcut.bn.bias
 (2048)" fillcolor=lightblue]
	140380010749280 -> 140380009797184
	140380009797184 [label=AccumulateGrad]
	140380009796896 -> 140380009796704
	140380010898912 [label="encoder.blocks.3.blocks.1.blocks.0.conv.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	140380010898912 -> 140380009796896
	140380009796896 [label=AccumulateGrad]
	140380009796656 -> 140380009796608
	140380010898992 [label="encoder.blocks.3.blocks.1.blocks.0.bn.weight
 (512)" fillcolor=lightblue]
	140380010898992 -> 140380009796656
	140380009796656 [label=AccumulateGrad]
	140380009796512 -> 140380009796608
	140380010899072 [label="encoder.blocks.3.blocks.1.blocks.0.bn.bias
 (512)" fillcolor=lightblue]
	140380010899072 -> 140380009796512
	140380009796512 [label=AccumulateGrad]
	140380009796416 -> 140380009796272
	140380010899472 [label="encoder.blocks.3.blocks.1.blocks.2.conv.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140380010899472 -> 140380009796416
	140380009796416 [label=AccumulateGrad]
	140380009796224 -> 140380009796176
	140380010899552 [label="encoder.blocks.3.blocks.1.blocks.2.bn.weight
 (512)" fillcolor=lightblue]
	140380010899552 -> 140380009796224
	140380009796224 [label=AccumulateGrad]
	140380009796080 -> 140380009796176
	140380010899632 [label="encoder.blocks.3.blocks.1.blocks.2.bn.bias
 (512)" fillcolor=lightblue]
	140380010899632 -> 140380009796080
	140380009796080 [label=AccumulateGrad]
	140380009795984 -> 140380009795840
	140380010900032 [label="encoder.blocks.3.blocks.1.blocks.4.conv.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140380010900032 -> 140380009795984
	140380009795984 [label=AccumulateGrad]
	140380009795792 -> 140380147449232
	140380010900112 [label="encoder.blocks.3.blocks.1.blocks.4.bn.weight
 (2048)" fillcolor=lightblue]
	140380010900112 -> 140380009795792
	140380009795792 [label=AccumulateGrad]
	140380009795744 -> 140380147449232
	140380010900192 [label="encoder.blocks.3.blocks.1.blocks.4.bn.bias
 (2048)" fillcolor=lightblue]
	140380010900192 -> 140380009795744
	140380009795744 [label=AccumulateGrad]
	140380009795696 -> 140380147448944
	140380147446544 -> 140380147449808
	140380010900592 [label="encoder.blocks.3.blocks.2.blocks.0.conv.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	140380010900592 -> 140380147446544
	140380147446544 [label=AccumulateGrad]
	140380147446880 -> 140380147446688
	140380010900672 [label="encoder.blocks.3.blocks.2.blocks.0.bn.weight
 (512)" fillcolor=lightblue]
	140380010900672 -> 140380147446880
	140380147446880 [label=AccumulateGrad]
	140380147445872 -> 140380147446688
	140380010900752 [label="encoder.blocks.3.blocks.2.blocks.0.bn.bias
 (512)" fillcolor=lightblue]
	140380010900752 -> 140380147445872
	140380147445872 [label=AccumulateGrad]
	140380147449184 -> 140380147446784
	140380010901152 [label="encoder.blocks.3.blocks.2.blocks.2.conv.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140380010901152 -> 140380147449184
	140380147449184 [label=AccumulateGrad]
	140380147447120 -> 140380147446832
	140380010901232 [label="encoder.blocks.3.blocks.2.blocks.2.bn.weight
 (512)" fillcolor=lightblue]
	140380010901232 -> 140380147447120
	140380147447120 [label=AccumulateGrad]
	140380147446928 -> 140380147446832
	140380010901312 [label="encoder.blocks.3.blocks.2.blocks.2.bn.bias
 (512)" fillcolor=lightblue]
	140380010901312 -> 140380147446928
	140380147446928 [label=AccumulateGrad]
	140380147446112 -> 140380147446400
	140380009709872 [label="encoder.blocks.3.blocks.2.blocks.4.conv.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140380009709872 -> 140380147446112
	140380147446112 [label=AccumulateGrad]
	140380147449520 -> 140380147449424
	140380009709952 [label="encoder.blocks.3.blocks.2.blocks.4.bn.weight
 (2048)" fillcolor=lightblue]
	140380009709952 -> 140380147449520
	140380147449520 [label=AccumulateGrad]
	140380147449568 -> 140380147449424
	140380009710032 [label="encoder.blocks.3.blocks.2.blocks.4.bn.bias
 (2048)" fillcolor=lightblue]
	140380009710032 -> 140380147449568
	140380147449568 [label=AccumulateGrad]
	140380147448944 -> 140380147448992
	140380147447888 -> 140380147448608
	140380147447888 [label=TBackward0]
	140380147449280 -> 140380147447888
	140380009990000 [label="decoder.decoder.weight
 (2, 2048)" fillcolor=lightblue]
	140380009990000 -> 140380147449280
	140380147449280 [label=AccumulateGrad]
	140380147448608 -> 140380010749360
}
